{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HolmesGPT","text":"<p>AI Agent for Troubleshooting Cloud-Native Environments.</p> <p></p>"},{"location":"#quick-start","title":"Quick Start","text":"<ul> <li> <p> Install CLI</p> <p>Testtt Run HolmesGPT from your terminal</p> <p> Install</p> </li> <li> <p> Install UI/TUI</p> <p>Use through a web interface or K9s plugin</p> <p> Install</p> </li> </ul>"},{"location":"#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> </ul>"},{"location":"cncf-self-assesment/","title":"General Technical Review - HolmesGPT / Sandbox","text":"<ul> <li>Project: HolmesGPT</li> <li>Project Version: 0.11.5</li> <li>Website: https://github.com/robusta-dev/holmesgpt</li> <li>Date Updated: 2025-07-16</li> <li>Template Version: v1.0</li> <li>Description: HolmesGPT is an AI agent that automates cloud-native troubleshooting, bridging knowledge gaps by investigating alerts, executing runbooks, and correlating observability data in cloud-native platforms.</li> </ul>"},{"location":"cncf-self-assesment/#day-0-planning-phase","title":"Day 0 - Planning Phase","text":""},{"location":"cncf-self-assesment/#scope","title":"Scope","text":"<p>Describe the roadmap process, how scope is determined for mid to long term features, as well as how the roadmap maps back to current contributions and maintainer ladder?</p> <p>HolmesGPT follows an open and community-driven roadmap process. The roadmap is maintained publicly (via GitHub Projects and issues) and is shaped by a combination of the following inputs:</p> <ul> <li>Community feedback from users and contributors, gathered through GitHub issues, Slack, and regular discussions</li> <li>Strategic alignment with the project\u2019s long-term mission: enabling AI-powered root cause analysis in cloud-native environments</li> <li>Technical priorities based on gaps surfaced during usage or contributor pain points</li> <li>Upstream integration plans with core CNCF projects like Prometheus, Kubernetes, and OpenTelemetry</li> </ul> <p>Mid to long-term scope is defined quarterly and iterated collaboratively among maintainers</p> <p>Describe the target persona or user(s) for the project? DevOps, SREs, and platform engineers</p> <p>Explain the primary use case for the project. What additional use cases are supported by the project?</p> <p>Two primary use cases: 1. Root-cause analysis of alerts (i.e. Prometheus alerts) 2. Troubleshooting problems (via free-text questions) in cloud-native environments</p> <p>In both cases, the analysis can be 100% autonomous, or driven by predefined runbooks.</p> <p>Explain which use cases have been identified as unsupported by the project. General purpose AI agent use cases (outside of troubleshooting and RCA), coding agents, and security use cases.</p> <p>Describe the intended types of organizations who would benefit from adopting this project. (i.e. financial services, any software manufacturer, organizations providing platform engineering services)?</p> <p>End users running cloud-native services at scale, especially in larger environments with many microservices and potential for complex cascading failures.</p> <p>Please describe any completed end user research and link to any reports. N/A</p>"},{"location":"cncf-self-assesment/#usability","title":"Usability","text":"<p>How should the target personas interact with your project? The most common entry point is via a cli tool that is run on-demand to troubleshoot a problem or an alert.</p> <p>Describe the user experience (UX) and user interface (UI) of the project. The open source includes a CLI tool with an interactive console and /slash commands. Several vendors have built graphical user interfaces on top of that.</p> <p>Describe how this project integrates with other projects in a production environment. The project exposes an HTTP API and a Helm chart for running the HTTP server in Kubernetes clusters.</p>"},{"location":"cncf-self-assesment/#design","title":"Design","text":"<p>Explain the design principles and best practices the project is following. * Human-in-the-loop: users are able to interact with and guide HolmesGPT investigations * Safety-first - The agent is restricted by default and only allowed to run safe commands. * Interoperable \u2013 works seamlessly with existing observability stacks * Kubernetes-native: Works with Prometheus, Loki, and other CNCF stack components. * Extensible: Modular plugin system for adding new data sources, including external MCP servers</p> <p>Outline or link to the project\u2019s architecture requirements? Describe how they differ for Proof of Concept, Development, Test and Production environments, as applicable. Lightweight, can run as a standalone local CLI or in-cluster as an HTTP server. Typical during POC users start with the local CLI and when rolling into production use a more advanced setup.</p> <p>Define any specific service dependencies the project relies on in the cluster. No relevant.</p> <p>Describe how the project implements Identity and Access Management. HolmesGPT runs with user-provided credentials (e.g. service account) and respects whichever permissions were given to it.</p> <p>Describe how the project has addressed sovereignty. HolmesGPT runs fully within the user\u2019s infrastructure. All data\u2014logs, metrics, traces, and AI-generated insights\u2014remains under user control. There\u2019s no dependency on external SaaS or third-party APIs unless explicitly configured. This ensures data privacy, compliance, and operational sovereignty.</p> <p>Regarding data sent to the LLM, here too users have the choice of providing their own LLM or using a trusted cloud provider of their choice.</p> <p>Describe any compliance requirements addressed by the project. N/A</p> <p>Describe the project\u2019s High Availability requirements. Each request to HolmesGPT is stateless, so it's possible to run multiple instances.</p> <p>Describe the project\u2019s resource requirements, including CPU, Network and Memory. Minimal, similar to any standard Python application running in a Kubernetes cluster. We recommend some defaults in the Helm chart, but this can be customized by the user.</p> <p>Describe the project\u2019s storage requirements, including its use of ephemeral and/or persistent storage. N/A</p> <p>Please outline the project\u2019s API Design The project itself exposes a REST API, following standard conventions. We strive to maintain backwards compatibility, and to add new endpoints when changing something instead of breaking an existing endpoint.</p> <p>It will perform HTTP calls to collect data when investigating problems - the exact calls depend on which data sources the user enabled.</p> <p>We bump the major release number only on breaking changes. Minor releases are done about monthly, when there are substantial new features. Bug fixes are done as needed with a patch release.</p> <p>Describe how the project is installed and initialized, e.g. a minimal install with a few lines of code or does it require more complex integration and configuration? Please refer to https://robusta-dev.github.io/holmesgpt/installation/cli-installation/</p> <p>How does an adopter test and validate the installation? Please refer to https://robusta-dev.github.io/holmesgpt/walkthrough/</p>"},{"location":"cncf-self-assesment/#security","title":"Security","text":"<p>Please provide a link to the project\u2019s cloud native security self assessment.</p> <p>Please review the Cloud Native Security Tenets from TAG Security. How are you satisfying the tenets of cloud native security projects? This is extremely relevant for us, given the risk that AI models can hallucinate and thereby that HolmesGPT could run malicious commands. To mitigate this, default access is read-only and non-mutating and limited to a pre-approved list of safe commands and integrations.</p> <p>Describe how each of the cloud native principles apply to your project. * Make security a design requirement - see above. * Applying secure configuration has the best user experience - also covered above * Selecting insecure configuration is a conscious decision -  Users must make a conscious and concerted effort to add insecure toolsets (data sources) to HolmesGPT - it cannot be done accidentally. * Transition from insecure to secure state is possible - users are free to reduce the permissions with which Holmes runs at any point in time and Holmes will identify it and adapt * Secure defaults are inherited - by default Holmes inherits service roles and permissions from its environment * Exception lists have first class support - users can add their own toolsets to give Holmes access to additional commands * Secure defaults protect against pervasive vulnerability exploits - in the case of Holmes, this is equivalent to providing security even when used with malicious/hallucinating LLM which is done as described above * Security limitations of a system are explainable - Holmes reports permission issues when encountered</p> <p>How do you recommend users alter security defaults in order to \"loosen\" the security of the project? Please link to any documentation the project has written concerning these use cases. https://robusta-dev.github.io/holmesgpt/data-sources/permissions/</p> <p>Security Hygiene We discuss security implications of features at the design phase, when working on new features. Where warranted there are dedicated discussions around security related aspects. Code reviews function as the final review, but very few issues reach that stage due to thinking about security earlier in the process.</p> <p>Explain the least minimal privileges required by the project and reasons for additional privileges. Read-only access to the data sources that are relevant to the requested RCA.</p> <p>Describe how the project is handling certificate rotation and mitigates any issues with certificates. Not relevant.</p> <p>Describe how the project is following and implementing secure software supply chain best practices Link is broken, but we strictly review all changes to CI/CD and anything that impacts building the project and distributing it to end users.</p>"},{"location":"ai-providers/","title":"AI Providers","text":"<p>HolmesGPT supports multiple AI providers, giving you flexibility in choosing the best model for your needs and budget.</p> <ul> <li> Anthropic</li> <li> AWS Bedrock</li> <li> Azure OpenAI</li> <li> Gemini</li> <li> Google Vertex AI</li> <li> Ollama</li> <li> OpenAI</li> <li> OpenAI-Compatible</li> </ul>"},{"location":"ai-providers/#quick-start","title":"Quick Start","text":"<p>Recommended for New Users</p> <p>OpenAI GPT-4o provides the best balance of accuracy and speed. Get started with:</p> <ol> <li>Get an OpenAI API key</li> <li>Set <code>export OPENAI_API_KEY=\"your-api-key\"</code></li> <li>Run <code>holmes ask \"what pods are failing?\"</code> (OpenAI is the default provider)</li> </ol> <p>Choose your provider above to see detailed configuration instructions.</p>"},{"location":"ai-providers/anthropic/","title":"Anthropic","text":"<p>Configure HolmesGPT to use Anthropic's Claude models.</p>"},{"location":"ai-providers/anthropic/#setup","title":"Setup","text":"<p>Get an Anthropic API key.</p>"},{"location":"ai-providers/anthropic/#configuration","title":"Configuration","text":"<pre><code>export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\nholmes ask \"what pods are failing?\" --model=\"anthropic/&lt;your-claude-model&gt;\"\n</code></pre>"},{"location":"ai-providers/anthropic/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"anthropic/&lt;your-claude-model&gt;\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/anthropic/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Anthropic provider. Refer to LiteLLM Anthropic docs for more details.</p>"},{"location":"ai-providers/aws-bedrock/","title":"AWS Bedrock","text":"<p>Configure HolmesGPT to use AWS Bedrock foundation models.</p>"},{"location":"ai-providers/aws-bedrock/#setup","title":"Setup","text":""},{"location":"ai-providers/aws-bedrock/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Install boto3: AWS Bedrock requires boto3 version 1.28.57 or higher:    <pre><code>pip install \"boto3&gt;=1.28.57\"\n</code></pre></p> </li> <li> <p>AWS credentials: Ensure you have AWS credentials configured with access to Bedrock models. See AWS Docs.</p> </li> </ol>"},{"location":"ai-providers/aws-bedrock/#configuration","title":"Configuration","text":""},{"location":"ai-providers/aws-bedrock/#environment-variables","title":"Environment Variables","text":"<pre><code>export AWS_REGION_NAME=\"us-east-1\"  # Replace with your region\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\n\nholmes ask \"what pods are failing?\" --model=\"bedrock/&lt;your-bedrock-model&gt;\"\n</code></pre>"},{"location":"ai-providers/aws-bedrock/#finding-your-aws-credentials","title":"Finding Your AWS Credentials","text":"<p>If the AWS CLI is already configured on your machine, you may be able to find the above values with:</p> <pre><code>cat ~/.aws/credentials ~/.aws/config\n</code></pre>"},{"location":"ai-providers/aws-bedrock/#finding-available-models","title":"Finding Available Models","text":"<p>To list models your account can access (replacing <code>us-east-1</code> with the relevant region):</p> <pre><code>aws bedrock list-foundation-models --region=us-east-1 | grep modelId\n</code></pre> <p>Important: Different models are available in different regions. For example, Claude Opus is only available in us-west-2.</p>"},{"location":"ai-providers/aws-bedrock/#model-name-examples","title":"Model Name Examples","text":"<p>Be sure to replace <code>&lt;your-bedrock-model&gt;</code> with a model you have access to, such as <code>anthropic.claude-3-5-sonnet-20240620-v1:0</code></p>"},{"location":"ai-providers/aws-bedrock/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support AWS Bedrock provider. Refer to LiteLLM Bedrock docs for more details.</p>"},{"location":"ai-providers/azure-openai/","title":"Azure OpenAI","text":"<p>Configure HolmesGPT to use Azure OpenAI Service.</p>"},{"location":"ai-providers/azure-openai/#setup","title":"Setup","text":"<p>Create an Azure OpenAI resource.</p>"},{"location":"ai-providers/azure-openai/#configuration","title":"Configuration","text":"<pre><code>export AZURE_API_VERSION=\"2024-02-15-preview\"\nexport AZURE_API_BASE=\"https://your-resource.openai.azure.com\"\nexport AZURE_API_KEY=\"your-azure-api-key\"\n\nholmes ask \"what pods are failing?\" --model=\"azure/&lt;your-deployment-name&gt;\"\n</code></pre>"},{"location":"ai-providers/azure-openai/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"azure/&lt;your-deployment-name&gt;\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/azure-openai/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Azure OpenAI provider. Refer to LiteLLM Azure docs for more details.</p>"},{"location":"ai-providers/gemini/","title":"Gemini","text":"<p>Configure HolmesGPT to use Google's Gemini models via Google AI Studio.</p>"},{"location":"ai-providers/gemini/#setup","title":"Setup","text":"<p>Get your API key from Google AI Studio.</p>"},{"location":"ai-providers/gemini/#configuration","title":"Configuration","text":"<pre><code>export GEMINI_API_KEY=\"your-gemini-api-key\"\nholmes ask \"what pods are failing?\" --model=\"gemini/&lt;your-gemini-model&gt;\"\n</code></pre>"},{"location":"ai-providers/gemini/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"gemini/&lt;your-gemini-model&gt;\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/gemini/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Gemini provider. Refer to LiteLLM Gemini docs for more details.</p>"},{"location":"ai-providers/google-vertex-ai/","title":"Google Vertex AI","text":"<p>Configure HolmesGPT to use Google Vertex AI with Gemini models.</p>"},{"location":"ai-providers/google-vertex-ai/#setup","title":"Setup","text":"<ol> <li>Create a Google Cloud project with Vertex AI API enabled</li> <li>Create a service account with <code>Vertex AI User</code> role</li> <li>Download the JSON key file</li> </ol>"},{"location":"ai-providers/google-vertex-ai/#configuration","title":"Configuration","text":"<pre><code>export VERTEXAI_PROJECT=\"your-project-id\"\nexport VERTEXAI_LOCATION=\"us-central1\"\nexport GOOGLE_APPLICATION_CREDENTIALS=\"path/to/service-account-key.json\"\n\nholmes ask \"what pods are failing?\" --model=\"vertex_ai/&lt;your-vertex-model&gt;\"\n</code></pre>"},{"location":"ai-providers/google-vertex-ai/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass credentials directly as command-line parameters:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"vertex_ai/&lt;your-vertex-model&gt;\" --api-key=\"your-service-account-key\"\n</code></pre>"},{"location":"ai-providers/google-vertex-ai/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Google Vertex AI provider. Refer to LiteLLM Google Vertex AI docs for more details.</p>"},{"location":"ai-providers/ollama/","title":"Ollama","text":"<p>Configure HolmesGPT to use local models with Ollama.</p> <p>Warning</p> <p>Ollama support is experimental. Tool-calling capabilities are limited and may produce inconsistent results. Only LiteLLM supported Ollama models work with HolmesGPT.</p>"},{"location":"ai-providers/ollama/#setup","title":"Setup","text":"<ol> <li>Download Ollama from ollama.com</li> <li>Start Ollama: <code>ollama serve</code></li> <li>Download models: <code>ollama pull &lt;model-name&gt;</code></li> </ol>"},{"location":"ai-providers/ollama/#configuration","title":"Configuration","text":"<pre><code>export OLLAMA_API_BASE=\"http://localhost:11434\"\nholmes ask \"what pods are failing?\" --model=\"ollama_chat/&lt;your-ollama-model&gt;\"\n</code></pre>"},{"location":"ai-providers/ollama/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also specify the model directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"ollama_chat/&lt;your-ollama-model&gt;\"\n</code></pre>"},{"location":"ai-providers/ollama/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support Ollama provider. Refer to LiteLLM Ollama docs for more details.</p>"},{"location":"ai-providers/openai-compatible/","title":"OpenAI-Compatible Models","text":"<p>Configure HolmesGPT to use any OpenAI-compatible API.</p> <p>Function Calling Required</p> <p>Your model and inference server must support function calling (tool calling). Models that lack this capability may produce incorrect results.</p>"},{"location":"ai-providers/openai-compatible/#requirements","title":"Requirements","text":"<ul> <li>Function calling support - OpenAI-style tool calling</li> <li>OpenAI-compatible API - Standard endpoints and request/response format</li> </ul>"},{"location":"ai-providers/openai-compatible/#supported-inference-servers","title":"Supported Inference Servers","text":"<ul> <li>llama-cpp-python</li> <li>LocalAI</li> <li>Text Generation WebUI (with OpenAI extension)</li> </ul>"},{"location":"ai-providers/openai-compatible/#configuration","title":"Configuration","text":"<pre><code>export OPENAI_API_BASE=\"http://localhost:8000/v1\"\nexport OPENAI_API_KEY=\"not-needed\"\nholmes ask \"what pods are failing?\" --model=\"openai/&lt;your-model&gt;\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also specify the model directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --model=\"openai/&lt;your-model&gt;\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#setup-examples","title":"Setup Examples","text":""},{"location":"ai-providers/openai-compatible/#localai","title":"LocalAI","text":"<pre><code>docker run -p 8080:8080 localai/localai:latest\nexport OPENAI_API_BASE=\"http://localhost:8080/v1\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#llama-cpp-python","title":"llama-cpp-python","text":"<pre><code>pip install 'llama-cpp-python[server]'\npython -m llama_cpp.server --model model.gguf --chat_format chatml\nexport OPENAI_API_BASE=\"http://localhost:8000/v1\"\nholmes ask \"analyze my deployment\" --model=openai/your-loaded-model\n</code></pre>"},{"location":"ai-providers/openai-compatible/#custom-ssl-certificates","title":"Custom SSL Certificates","text":"<p>If your LLM provider uses a custom Certificate Authority (CA):</p> <pre><code># Base64 encode your certificate and set it as an environment variable\nexport CERTIFICATE=\"base64-encoded-cert-here\"\n</code></pre>"},{"location":"ai-providers/openai-compatible/#known-limitations","title":"Known Limitations","text":"<ul> <li>vLLM: Does not yet support function calling</li> <li>Text Generation WebUI: Requires OpenAI extension enabled</li> <li>Some models: May hallucinate responses instead of reporting function calling limitations</li> </ul>"},{"location":"ai-providers/openai-compatible/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support OpenAI-compatible providers. Refer to LiteLLM OpenAI-compatible docs for more details.</p>"},{"location":"ai-providers/openai/","title":"OpenAI","text":"<p>Configure HolmesGPT to use OpenAI's GPT models.</p>"},{"location":"ai-providers/openai/#setup","title":"Setup","text":"<p>Get a paid OpenAI API key.</p> <p>Note</p> <p>Requires a paid OpenAI API key, not a ChatGPT Plus subscription.</p>"},{"location":"ai-providers/openai/#configuration","title":"Configuration","text":"<pre><code>export OPENAI_API_KEY=\"your-openai-api-key\"\nholmes ask \"what pods are failing?\"\n</code></pre>"},{"location":"ai-providers/openai/#using-cli-parameters","title":"Using CLI Parameters","text":"<p>You can also pass the API key directly as a command-line parameter:</p> <pre><code>holmes ask \"what pods are failing?\" --api-key=\"your-api-key\"\n</code></pre>"},{"location":"ai-providers/openai/#available-models","title":"Available Models","text":"<pre><code># GPT-4o (default, recommended)\nholmes ask \"what pods are failing?\"\n\n# GPT-4o mini (faster, but results are not as accurate)\nholmes ask \"what pods are failing?\" --model=\"gpt-4o-mini\"\n</code></pre>"},{"location":"ai-providers/openai/#additional-resources","title":"Additional Resources","text":"<p>HolmesGPT uses the LiteLLM API to support OpenAI provider. Refer to LiteLLM OpenAI docs for more details.</p>"},{"location":"data-sources/","title":"Data Sources","text":"<p>HolmesGPT connects to your monitoring and observability tools to provide comprehensive root cause analysis.</p>"},{"location":"data-sources/#available-options","title":"Available Options","text":"<ul> <li> <p>Built-in Toolsets</p> <p>Pre-configured integrations for popular tools like Prometheus, Grafana, DataDog, and more.</p> </li> <li> <p>Custom Toolsets</p> <p>Create your own integrations for proprietary or specialized tools.</p> </li> <li> <p>Remote MCP Servers</p> <p>Connect to Model Context Protocol servers for extended capabilities.</p> </li> </ul>"},{"location":"data-sources/custom-toolsets/","title":"Custom Toolsets","text":"<p>If the built-in toolsets don't meet your needs, you can extend HolmesGPT's investigation capabilities by creating custom toolsets. This is especially useful for unique use cases, proprietary tools, or specialized infrastructure setups. Examples include advanced log analysis tools, external monitoring integrations, or custom diagnostic scripts.</p> <p>By creating custom toolsets, you can ensure HolmesGPT has access to all the data sources and tools necessary for thorough investigations in your specific environment.</p>"},{"location":"data-sources/custom-toolsets/#examples","title":"Examples","text":"<p>Below are three examples of how to create custom toolsets for different scenarios.</p>"},{"location":"data-sources/custom-toolsets/#example-1-grafana-toolset","title":"Example 1: Grafana Toolset","text":"<p>This example creates a toolset that helps HolmesGPT view and suggest relevant Grafana dashboards.</p> Holmes CLIRobusta Helm Chart <p>Configuration File (<code>toolsets.yaml</code>):</p> <pre><code>toolsets:\n  grafana:\n    description: \"View and suggest Grafana dashboards\"\n    prerequisites: \"Grafana instance accessible from HolmesGPT\"\n    tags: [monitoring, observability]\n    installation: |\n      1. Ensure Grafana is accessible from HolmesGPT\n      2. Configure Grafana API credentials if authentication is required\n    tools:\n      - name: view_dashboard\n        description: \"View a specific Grafana dashboard by ID or name\"\n        command: |\n          curl -s \"${GRAFANA_URL}/api/dashboards/uid/{{ dashboard_uid }}\" \\\n            -H \"Authorization: Bearer ${GRAFANA_TOKEN}\"\n        additionalInstructions: |\n          Parse the JSON response to extract dashboard information.\n          If dashboard is not found, suggest similar dashboards.\n\n      - name: search_dashboards\n        description: \"Search for dashboards related to specific keywords\"\n        command: |\n          curl -s \"${GRAFANA_URL}/api/search?query={{ search_query }}\" \\\n            -H \"Authorization: Bearer ${GRAFANA_TOKEN}\"\n        additionalInstructions: |\n          Return the most relevant dashboards based on the search query.\n          Include dashboard URLs for easy access.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GRAFANA_URL=\"http://grafana.monitoring.svc.cluster.local:3000\"\nexport GRAFANA_TOKEN=\"your-grafana-api-token\"\n</code></pre> <p>Run HolmesGPT:</p> <pre><code>holmes ask \"show me dashboards related to CPU usage\" --toolsets=toolsets.yaml\n</code></pre> <p>After making changes to your toolsets file, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n  customToolsets:\n    grafana:\n      description: \"View and suggest Grafana dashboards\"\n      prerequisites: \"Grafana instance accessible from HolmesGPT\"\n      tags: [monitoring, observability]\n      installation: |\n        1. Ensure Grafana is accessible from HolmesGPT\n        2. Configure Grafana API credentials if authentication is required\n      tools:\n        - name: view_dashboard\n          description: \"View a specific Grafana dashboard by ID or name\"\n          command: |\n            curl -s \"{{ grafana_url }}/api/dashboards/uid/{{ dashboard_uid }}\" \\\n              -H \"Authorization: Bearer {{ grafana_token }}\"\n          additionalInstructions: |\n            Parse the JSON response to extract dashboard information.\n            If dashboard is not found, suggest similar dashboards.\n\n        - name: search_dashboards\n          description: \"Search for dashboards related to specific keywords\"\n          command: |\n            curl -s \"{{ grafana_url }}/api/search?query={{ search_query }}\" \\\n              -H \"Authorization: Bearer {{ grafana_token }}\"\n          additionalInstructions: |\n            Return the most relevant dashboards based on the search query.\n            Include dashboard URLs for easy access.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GRAFANA_URL=\"http://grafana.monitoring.svc.cluster.local:3000\"\nexport GRAFANA_TOKEN=\"your-grafana-api-token\"\n</code></pre> <p>Helm Upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/custom-toolsets/#example-2-kubernetes-diagnostics-toolset","title":"Example 2: Kubernetes Diagnostics Toolset","text":"<p>This example creates a toolset with advanced diagnostic tools for Kubernetes clusters.</p> Holmes CLIRobusta Helm Chart <p>Configuration File (<code>toolsets.yaml</code>):</p> <pre><code>toolsets:\n  k8s-diagnostics:\n    description: \"Advanced Kubernetes diagnostic tools\"\n    prerequisites: \"kubectl access to the cluster\"\n    tags: [kubernetes, diagnostics]\n    installation: |\n      1. Ensure kubectl is configured with cluster access\n      2. Verify necessary RBAC permissions are in place\n    tools:\n      - name: check_node_pressure\n        description: \"Check for node pressure conditions and resource usage\"\n        command: |\n          kubectl get nodes -o json | jq -r '\n            .items[] |\n            select(.status.conditions[]? | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .status == \"True\") |\n            .metadata.name + \": \" + (.status.conditions[] | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .type + \" = \" + .status)\n          '\n        additionalInstructions: |\n          If any nodes show pressure conditions, investigate further and suggest remediation steps.\n\n      - name: analyze_pod_distribution\n        description: \"Analyze pod distribution across nodes in a namespace\"\n        command: |\n          kubectl get pods -n {{ namespace }} -o wide --no-headers |\n          awk '{print $7}' | sort | uniq -c | sort -nr\n        additionalInstructions: |\n          Check for uneven pod distribution that might indicate scheduling issues.\n          Suggest rebalancing if necessary.\n\n      - name: check_resource_quotas\n        description: \"Check resource quota usage in a namespace\"\n        command: |\n          kubectl describe resourcequota -n {{ namespace }}\n        additionalInstructions: |\n          Alert if resource quotas are close to limits. Suggest scaling or quota adjustments.\n</code></pre> <p>Run HolmesGPT:</p> <pre><code>holmes ask \"check for any resource pressure in the cluster\" --toolsets=toolsets.yaml\n</code></pre> <p>After making changes to your toolsets file, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n  customToolsets:\n    k8s-diagnostics:\n      description: \"Advanced Kubernetes diagnostic tools\"\n      prerequisites: \"kubectl access to the cluster\"\n      tags: [kubernetes, diagnostics]\n      installation: |\n        1. Ensure kubectl is configured with cluster access\n        2. Verify necessary RBAC permissions are in place\n      tools:\n        - name: check_node_pressure\n          description: \"Check for node pressure conditions and resource usage\"\n          command: |\n            kubectl get nodes -o json | jq -r '\n              .items[] |\n              select(.status.conditions[]? | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .status == \"True\") |\n              .metadata.name + \": \" + (.status.conditions[] | select(.type == \"MemoryPressure\" or .type == \"DiskPressure\" or .type == \"PIDPressure\") | .type + \" = \" + .status)\n            '\n          additionalInstructions: |\n            If any nodes show pressure conditions, investigate further and suggest remediation steps.\n\n        - name: analyze_pod_distribution\n          description: \"Analyze pod distribution across nodes in a namespace\"\n          command: |\n            kubectl get pods -n {{ namespace }} -o wide --no-headers |\n            awk '{print $7}' | sort | uniq -c | sort -nr\n          additionalInstructions: |\n            Check for uneven pod distribution that might indicate scheduling issues.\n            Suggest rebalancing if necessary.\n\n        - name: check_resource_quotas\n          description: \"Check resource quota usage in a namespace\"\n          command: |\n            kubectl describe resourcequota -n {{ namespace }}\n          additionalInstructions: |\n            Alert if resource quotas are close to limits. Suggest scaling or quota adjustments.\n</code></pre> <p>Helm Upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/custom-toolsets/#example-3-github-toolset","title":"Example 3: GitHub Toolset","text":"<p>This example shows how to create a toolset for fetching information from GitHub repositories.</p> Holmes CLIRobusta Helm Chart <p>Configuration File (<code>toolsets.yaml</code>):</p> <pre><code>toolsets:\n  github:\n    description: \"Fetch information from GitHub repositories\"\n    prerequisites: \"GitHub API token with repository access\"\n    tags: [source-control, github]\n    installation: |\n      1. Create a GitHub personal access token\n      2. Set the token as an environment variable\n      3. Ensure network access to GitHub API\n    tools:\n      - name: get_repository_info\n        description: \"Get information about a GitHub repository\"\n        command: |\n          curl -s -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n            \"https://api.github.com/repos/{{ owner }}/{{ repo }}\"\n        additionalInstructions: |\n          Extract relevant repository information like description, language, last update.\n          Check for any security alerts or issues.\n\n      - name: get_recent_commits\n        description: \"Get recent commits from a repository\"\n        command: |\n          curl -s -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n            \"https://api.github.com/repos/{{ owner }}/{{ repo }}/commits?per_page={{ limit | default(10) }}\"\n        additionalInstructions: |\n          Show commit messages, authors, and timestamps.\n          Look for patterns that might relate to the current issue.\n\n      - name: search_issues\n        description: \"Search for issues in a repository\"\n        command: |\n          curl -s -H \"Authorization: token ${GITHUB_TOKEN}\" \\\n            \"https://api.github.com/search/issues?q=repo:{{ owner }}/{{ repo }}+{{ search_query }}\"\n        additionalInstructions: |\n          Find relevant issues that might be related to the current problem.\n          Include issue titles, states, and URLs.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GITHUB_TOKEN=\"your-github-personal-access-token\"\n</code></pre> <p>Run HolmesGPT:</p> <pre><code>holmes ask \"check recent commits in robusta-dev/robusta repository\" --toolsets=toolsets.yaml\n</code></pre> <p>After making changes to your toolsets file, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n  customToolsets:\n    github:\n      description: \"Fetch information from GitHub repositories\"\n      prerequisites: \"GitHub API token with repository access\"\n      tags: [source-control, github]\n      installation: |\n        1. Create a GitHub personal access token\n        2. Set the token as an environment variable\n        3. Ensure network access to GitHub API\n      tools:\n        - name: get_repository_info\n          description: \"Get information about a GitHub repository\"\n          command: |\n            curl -s -H \"Authorization: token {{ github_token }}\" \\\n              \"https://api.github.com/repos/{{ owner }}/{{ repo }}\"\n          additionalInstructions: |\n            Extract relevant repository information like description, language, last update.\n            Check for any security alerts or issues.\n\n        - name: get_recent_commits\n          description: \"Get recent commits from a repository\"\n          command: |\n            curl -s -H \"Authorization: token {{ github_token }}\" \\\n              \"https://api.github.com/repos/{{ owner }}/{{ repo }}/commits?per_page={{ limit | default(10) }}\"\n          additionalInstructions: |\n            Show commit messages, authors, and timestamps.\n            Look for patterns that might relate to the current issue.\n\n        - name: search_issues\n          description: \"Search for issues in a repository\"\n          command: |\n            curl -s -H \"Authorization: token {{ github_token }}\" \\\n              \"https://api.github.com/search/issues?q=repo:{{ owner }}/{{ repo }}+{{ search_query }}\"\n          additionalInstructions: |\n            Find relevant issues that might be related to the current problem.\n            Include issue titles, states, and URLs.\n</code></pre> <p>Environment Variables:</p> <pre><code>export GITHUB_TOKEN=\"your-github-personal-access-token\"\n</code></pre> <p>Helm Upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/custom-toolsets/#reference","title":"Reference","text":""},{"location":"data-sources/custom-toolsets/#toolset-configuration","title":"Toolset Configuration","text":"<p>A custom toolset consists of the following components:</p> <pre><code>toolsets:\n  &lt;toolset-name&gt;:\n    description: \"Human-readable description\"\n    prerequisites: \"What needs to be installed/configured\"\n    tags: [tag1, tag2]  # Optional: for categorization\n    installation: |\n      Multi-line installation instructions\n    tools:\n      - name: tool_name\n        description: \"What this tool does\"\n        command: |\n          Command or script to execute\n        parameters:  # Optional: can be inferred by LLM\n          - name: param_name\n            description: \"Parameter description\"\n        additionalInstructions: |\n          Instructions for post-processing the command output\n</code></pre>"},{"location":"data-sources/custom-toolsets/#tool-configuration","title":"Tool Configuration","text":"<p>Each tool within a toolset can be configured with:</p> <ul> <li>name: Unique identifier for the tool</li> <li>description: What the tool does (visible to the AI)</li> <li>command: Shell command or script to execute</li> <li>parameters: Optional parameter definitions (usually inferred)</li> <li>additionalInstructions: How to interpret/process the output</li> </ul>"},{"location":"data-sources/custom-toolsets/#variable-syntax","title":"Variable Syntax","text":"<p>HolmesGPT supports two types of variables in commands:</p> <ul> <li><code>{{ variable }}</code>: Dynamic variables inferred by the LLM based on context</li> <li><code>${VARIABLE}</code>: Environment variables (not visible to the LLM)</li> </ul>"},{"location":"data-sources/custom-toolsets/#tags","title":"Tags","text":"<p>Optional tags help categorize toolsets:</p> <ul> <li>core: Essential system tools</li> <li>cluster: Cluster-specific tools</li> <li>monitoring: Observability tools</li> <li>networking: Network-related tools</li> <li>storage: Storage-related tools</li> </ul>"},{"location":"data-sources/custom-toolsets/#advanced-adding-custom-binaries","title":"Advanced: Adding Custom Binaries","text":"<p>If your custom toolset requires additional binaries not available in the base HolmesGPT image, you can extend the Docker image:</p>"},{"location":"data-sources/custom-toolsets/#create-a-custom-dockerfile","title":"Create a Custom Dockerfile","text":"<pre><code>FROM us-central1-docker.pkg.dev/genuine-flight-317411/devel/holmes:latest\n\n# Install additional tools\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    your-custom-tool \\\n    another-binary \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy custom scripts\nCOPY scripts/ /usr/local/bin/\n\n# Make scripts executable\nRUN chmod +x /usr/local/bin/*.sh\n</code></pre>"},{"location":"data-sources/custom-toolsets/#build-and-push-your-image","title":"Build and Push Your Image","text":"<pre><code>docker build -t your-registry/holmes-custom:latest .\ndocker push your-registry/holmes-custom:latest\n</code></pre>"},{"location":"data-sources/custom-toolsets/#use-custom-image-in-helm-values","title":"Use Custom Image in Helm Values","text":"<pre><code>holmes:\n  image:\n    repository: your-registry/holmes-custom\n    tag: latest\n  customToolsets:\n    # Your custom toolset configuration\n</code></pre> <p>This approach allows you to include any additional tools or dependencies your custom toolsets might need.</p>"},{"location":"data-sources/permissions/","title":"Adding Permissions for Additional Resources","text":"<p>HolmesGPT may require access to additional Kubernetes resources or CRDs for specific analyses. Permissions can be extended by modifying the ClusterRole rules. The default configuration has limited resource access.</p>"},{"location":"data-sources/permissions/#common-scenarios-for-adding-permissions","title":"Common Scenarios for Adding Permissions","text":"<ol> <li>External Integrations and CRDs - Access to custom resources from ArgoCD, Istio, etc.</li> <li>Additional Kubernetes resources - Resources not included in the default permissions</li> </ol>"},{"location":"data-sources/permissions/#example-scenario-adding-argo-cd-permissions","title":"Example Scenario: Adding Argo CD Permissions","text":"<p>To enable HolmesGPT to analyze ArgoCD applications and projects, you need to add permissions for ArgoCD custom resources.</p>"},{"location":"data-sources/permissions/#steps-to-add-permissions","title":"Steps to Add Permissions","text":"<ol> <li> <p>Update <code>generated_values.yaml</code> with custom cluster role rules:</p> <pre><code>enableHolmesGPT: true\nholmes:\n  customClusterRoleRules:\n    - apiGroups: [\"argoproj.io\"]\n      resources: [\"applications\", \"appprojects\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> </li> <li> <p>Apply configuration using Helm:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre> </li> </ol>"},{"location":"data-sources/permissions/#key-benefits","title":"Key Benefits","text":"<ul> <li>Enables HolmesGPT to analyze specific Kubernetes resources</li> <li>Allows interaction with custom resources and CRDs</li> <li>Provides more comprehensive troubleshooting capabilities</li> </ul> <p>The configuration provides flexibility to extend HolmesGPT's permissions to suit specific cluster and tooling requirements.</p>"},{"location":"data-sources/remote-mcp-servers/","title":"Remote MCP Servers","text":"<p>Warning</p> <p>Remote MCP servers are in Tech Preview stage.</p> <p>HolmesGPT can integrate with remote MCP servers using SSE mode. This capability enables HolmesGPT to access external data sources and tools in real time. This guide provides step-by-step instructions for configuring HolmesGPT to connect with remote MCP servers over SSE.</p>"},{"location":"data-sources/remote-mcp-servers/#example-mcp-server-configuration","title":"Example: MCP server configuration","text":"Robusta Helm Chart <p>Helm Values:</p> <pre><code>holmes:\n  mcp_servers:\n    mcp_server_1:\n      # human-readable description of the mcp server (this is not seen by the AI model - its just for users)\n      description: \"Remote mcp server\"\n      url: \"http://example.com:8000/sse\"\n\n    mcp_server_2:\n      description: \"MCP server that runs in my cluster\"\n      url: \"http://&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local:&lt;service-port&gt;\"\n      config:\n        headers:\n          key: \"{{ env.my_mcp_server_key }}\" # You can use holmes environment variables as headers for the MCP server requests.\n</code></pre> <p>Update your Helm values with the provided YAML configuration, then apply the changes with Helm upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre>"},{"location":"data-sources/remote-mcp-servers/#example-working-with-stdio-mcp-servers","title":"Example: Working with Stdio MCP servers","text":"<p>MCP currently supports three transport mechanisms: stdio, Server-Sent Events (SSE), and Streamable HTTP. At this time, HolmesGPT is compatible only with MCP servers that use SSE. However, many existing MCP servers\u2014such as Dynatrace MCP\u2014rely exclusively on the stdio transport. To overcome this incompatibility, tools like Supergateway can act as a bridge by converting stdio-based MCPs into SSE-compatible endpoints.</p> <p>For this demo we will use: - Dynatrace MCP - Supergateway - runs MCP stdio-based servers over SSE</p> <p>Check out supergatway docs to find out other useful flags.</p> <p>See it in action</p>"},{"location":"data-sources/remote-mcp-servers/#1-run-stdio-mcp-as-sse","title":"1. Run stdio MCP as SSE","text":"DockerKubernetes Pod <p>This command runs the Dynatrace MCP server locally via Docker using Supergateway to wrap it with SSE support. Credentials (e.g., API keys) should be stored in a .env file passed to Docker using --env-file. you can change <code>\"npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\"</code> to your specific MCP.</p> <pre><code>docker run --env-file .env -it --rm -p  8003:8003 supercorp/supergateway \\\n--stdio \"npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\" \\\n--port 8003 \\\n--logLevel debug\n</code></pre> <p>Once the container starts, you should see logs similar to:</p> <pre><code>[supergateway] Starting...\n[supergateway] Supergateway is supported by Supermachine (hosted MCPs) - https://supermachine.ai\n[supergateway]   - outputTransport: sse\n[supergateway]   - Headers: (none)\n[supergateway]   - port: 8003\n[supergateway]   - stdio: npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\n[supergateway]   - ssePath: /sse\n[supergateway]   - messagePath: /message\n[supergateway]   - CORS: disabled\n[supergateway]   - Health endpoints: (none)\n[supergateway] Listening on port 8003\n[supergateway] SSE endpoint: http://localhost:8003/sse\n[supergateway] POST messages: http://localhost:8003/message\n</code></pre> <p>This will run dynatrace MCP server as a pod in your cluster. credentials are passed as env vars.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: dynatrace-mcp\n  labels:\n    app: dynatrace-mcp\nspec:\n  containers:\n    - name: supergateway\n      image: supercorp/supergateway\n      env:\n        - name: DT_ENVIRONMENT\n          value: https://abcd1234.apps.dynatrace.com\n        - name: OAUTH_CLIENT_ID\n          value: dt0s02.SAMPLE\n        - name: OAUTH_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: dynatrace-credentials\n              key: client_secret\n      ports:\n        - containerPort: 8003\n      args:\n        - \"--stdio\"\n        - \"npx -y @dynatrace-oss/dynatrace-mcp-server@latest /\"\n        - \"--port\"\n        - \"8003\"\n        - \"--logLevel\"\n        - \"debug\"\n      stdin: true\n      tty: true\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dynatrace-mcp\nspec:\n  selector:\n    app: dynatrace-mcp\n  ports:\n    - protocol: TCP\n      port: 8003\n      targetPort: 8003\n  type: ClusterIP\n</code></pre>"},{"location":"data-sources/remote-mcp-servers/#2-add-mcp-server-to-holmes-config","title":"2. Add MCP server to holmes config","text":"<p>With the MCP server running in SSE mode, we need to let HolmesGPT know of the mcp server. Use this config according to your use case.</p> <p>Configuration:</p> Holmes CLIRobusta Helm Chart <p>Use a config file, and pass it when running cli commands.</p> <p>custom_toolset.yaml:</p> <pre><code>mcp_servers:\n  mcp_server_1:\n    description: \"Dynatrace observability platform. Bring real-time observability data directly into your development workflow.\"\n    url: \"http://localhost:8003/sse\"\n</code></pre> <p>You can now use Holmes via the CLI with your configured MCP server. For example:</p> <pre><code>holmes ask -t custom_toolset.yaml  \"Using dynatrace what issues do I have in my cluster?\"\n</code></pre> <p>Helm Values:</p> <pre><code>holmes:\n  mcp_servers:\n    mcp_server_1:\n      description: \"Dynatrace observability platform. Bring real-time observability data directly into your development workflow.\"\n      url: \"http://dynatrace-mcp.default.svc.cluster.local:8003\"\n</code></pre> <p>Update your Helm values with the provided YAML configuration, then apply the changes with Helm upgrade:</p> <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre> <p>After the deployment is complete, you can open the HolmesGPT chat in the Robusta SaaS UI and ask questions like Using dynatrace what issues do I have in my cluster?.</p>"},{"location":"data-sources/builtin-toolsets/","title":"Built-in Toolsets","text":"<p>HolmesGPT includes pre-built integrations for popular monitoring and observability tools. Some work automatically with Kubernetes, while others require API keys or configuration.</p>"},{"location":"data-sources/builtin-toolsets/#available-toolsets","title":"Available Toolsets","text":"<ul> <li> AKS Node Health</li> <li> ArgoCD</li> <li> AWS</li> <li> Azure Kubernetes Service</li> <li> Azure SQL Database</li> <li> Confluence</li> <li> Coralogix logs</li> <li> Datadog</li> <li> Datetime</li> <li> Docker</li> <li> GitHub</li> <li> Grafana Loki</li> <li> Grafana Tempo</li> <li> Helm</li> <li> Internet</li> <li> Kafka</li> <li> Kubernetes</li> <li> MongoDB Atlas</li> <li> New Relic</li> <li> Notion</li> <li> OpenSearch logs</li> <li> OpenSearch status</li> <li> Prometheus</li> <li> RabbitMQ</li> <li> Robusta</li> <li> ServiceNow</li> <li> Slab</li> </ul>"},{"location":"data-sources/builtin-toolsets/#getting-started","title":"Getting Started","text":"<ol> <li>Choose toolsets that match your infrastructure (Prometheus, Grafana, etc.)</li> <li>Configure authentication - some need API keys, others work automatically</li> <li>Run a test investigation to verify data access</li> </ol> <p>\ud83d\udca1 Tip: Start with Kubernetes and Prometheus for basic cluster monitoring.</p>"},{"location":"data-sources/builtin-toolsets/aks-node-health/","title":"AKS Node Health","text":"<p>By enabling this toolset, HolmesGPT will be able to perform specialized health checks and troubleshooting for Azure Kubernetes Service (AKS) nodes, including node-specific diagnostics and performance analysis.</p>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#prerequisites","title":"Prerequisites","text":"<ol> <li>Azure CLI installed and configured</li> <li>Appropriate Azure RBAC permissions for AKS clusters</li> <li>Access to the target AKS cluster</li> <li>Node-level access permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, ensure you're authenticated with Azure:</p> <pre><code>az login\naz account set --subscription \"&lt;your subscription id&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  aks/node-health:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\"\n      resource_group: \"&lt;your AKS resource group&gt;\"\n      cluster_name: \"&lt;your AKS cluster name&gt;\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    aks/node-health:\n      enabled: true\n      config:\n        subscription_id: \"&lt;your Azure subscription ID&gt;\"\n        resource_group: \"&lt;your AKS resource group&gt;\"\n        cluster_name: \"&lt;your AKS cluster name&gt;\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure additional health check parameters:</p> <pre><code>toolsets:\n  aks/node-health:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\"\n      resource_group: \"&lt;your AKS resource group&gt;\"\n      cluster_name: \"&lt;your AKS cluster name&gt;\"\n      health_check_interval: 300  # Health check interval in seconds\n      max_unhealthy_nodes: 3  # Maximum number of unhealthy nodes to report\n</code></pre>"},{"location":"data-sources/builtin-toolsets/aks-node-health/#capabilities","title":"Capabilities","text":"Tool Name Description aks_check_node_health Perform comprehensive health checks on AKS nodes aks_get_node_metrics Get detailed metrics for AKS nodes aks_diagnose_node_issues Diagnose common node-level issues aks_check_node_readiness Check if nodes are ready and schedulable aks_get_node_events Get events related to specific nodes aks_check_node_resources Check resource utilization on nodes"},{"location":"data-sources/builtin-toolsets/aks/","title":"Azure Kubernetes Service (AKS)","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with Azure Kubernetes Service clusters, providing Azure-specific troubleshooting capabilities and cluster management.</p>"},{"location":"data-sources/builtin-toolsets/aks/#prerequisites","title":"Prerequisites","text":"<ol> <li>Azure CLI installed and configured</li> <li>Appropriate Azure RBAC permissions for AKS clusters</li> <li>Access to the target AKS cluster</li> </ol>"},{"location":"data-sources/builtin-toolsets/aks/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, ensure you're authenticated with Azure:</p> <pre><code>az login\naz account set --subscription \"&lt;your subscription id&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  aks/core:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\" # Optional\n      resource_group: \"&lt;your AKS resource group&gt;\" # Optional\n      cluster_name: \"&lt;your AKS cluster name&gt;\" # Optional\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    aks/core:\n      enabled: true\n      config:\n        subscription_id: \"&lt;your Azure subscription ID&gt;\"\n        resource_group: \"&lt;your AKS resource group&gt;\"\n        cluster_name: \"&lt;your AKS cluster name&gt;\"\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/aks/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure additional Azure settings:</p> <pre><code>toolsets:\n  aks/core:\n    enabled: true\n    config:\n      subscription_id: \"&lt;your Azure subscription ID&gt;\"\n      resource_group: \"&lt;your AKS resource group&gt;\"\n      cluster_name: \"&lt;your AKS cluster name&gt;\"\n      location: \"eastus\"  # Azure region\n      timeout: 60  # Request timeout in seconds\n</code></pre>"},{"location":"data-sources/builtin-toolsets/aks/#capabilities","title":"Capabilities","text":"Tool Name Description aks_get_cluster_info Get detailed information about the AKS cluster aks_get_node_pools List and describe AKS node pools aks_get_cluster_credentials Get cluster credentials for kubectl access aks_scale_node_pool Scale a specific node pool aks_get_cluster_logs Fetch AKS cluster logs aks_get_addon_status Get status of AKS addons"},{"location":"data-sources/builtin-toolsets/argocd/","title":"ArgoCD","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch the status, deployment history, and configuration of ArgoCD applications.</p>"},{"location":"data-sources/builtin-toolsets/argocd/#configuration","title":"Configuration","text":"<p>This toolset requires an <code>ARGOCD_AUTH_TOKEN</code> environment variable. Generate such auth token by following these steps.</p> <p>You can consult the available environment variables on ArgoCD's official documentation for the CLI.</p> <p>The permissions required are below (<code>kubectl edit configmap argocd-rbac-cm -n argocd</code>). You can consult ArgoCD's documentation on user creation and permissions.</p> <pre><code># Ensure this data block is present in your argocd-rbac-cm configmap.\n# It enables the permissions for holmes to fetch the data it needs to\n# investigate argocd issues.\n#\n# These permissions depend on a new user `holmesgpt` being created,\n# for example using the `argocd-cm` configmap\ndata:\n  policy.default: role:readonly\n  policy.csv: |\n    p, role:admin, *, *, *, allow\n    p, role:admin, accounts, apiKey, *, allow\n    p, holmesgpt, accounts, apiKey, holmesgpt, allow\n    p, holmesgpt, projects, get, *, allow\n    p, holmesgpt, applications, get, *, allow\n    p, holmesgpt, repositories, get, *, allow\n    p, holmesgpt, clusters, get, *, allow\n    p, holmesgpt, applications, manifests, */*, allow\n    p, holmesgpt, applications, resources, */*, allow\n    g, admin, role:admin\n</code></pre>"},{"location":"data-sources/builtin-toolsets/argocd/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description argocd_app_list List ArgoCD applications argocd_app_get Get details of a specific ArgoCD application argocd_app_diff Show differences between live and desired state argocd_app_manifests Get manifests for an ArgoCD application argocd_app_resources Get resources for an ArgoCD application"},{"location":"data-sources/builtin-toolsets/aws/","title":"AWS","text":""},{"location":"data-sources/builtin-toolsets/aws/#security","title":"Security","text":"<p>Set of tools to audit AWS CloudTrail events and audit logs.</p>"},{"location":"data-sources/builtin-toolsets/aws/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, add the following environment variables:</p> <pre><code>export AWS_ACCESS_KEY_ID=\"&lt;your AWS access key ID&gt;\"\nexport AWS_SECRET_ACCESS_KEY=\"&lt;your AWS secret access key&gt;\"\nexport AWS_DEFAULT_REGION=\"us-west-2\"\n</code></pre> <p>Then, Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    aws/security:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Are there any security misconfigurations in my signup application, particularly in the database?\"\n</code></pre> <p>This builtin toolset is currently only available in HolmesGPT CLI.</p>"},{"location":"data-sources/builtin-toolsets/aws/#capabilities","title":"Capabilities","text":"Tool Name Description aws_cloudtrail_event_lookup Fetches events of a specified type from AWS CloudTrail along with the users that called them aws_cloudtrail_event_details Fetches and returns full event details for an AWS CloudTrail event in JSON format given an event ID aws_user_audit_logs Fetches audit logs for a specified user from AWS CloudTrail in the past 24 hours. Provide username as was output by aws_event_lookup or aws_event_details"},{"location":"data-sources/builtin-toolsets/aws/#rds","title":"RDS","text":"<p>Read access to Amazon RDS instances, events, and logs.</p>"},{"location":"data-sources/builtin-toolsets/aws/#configuration_1","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Configure RDS access with your AWS credentials and region settings.</p> <p>This builtin toolset is currently only available in HolmesGPT CLI.</p>"},{"location":"data-sources/builtin-toolsets/aws/#capabilities_1","title":"Capabilities","text":"Tool Name Description aws_rds_describe_instances Describe RDS instances aws_rds_events Get RDS events aws_rds_logs Retrieve RDS logs"},{"location":"data-sources/builtin-toolsets/azure-sql/","title":"Azure SQL Database","text":"<p>By enabling this toolset, HolmesGPT can analyze Azure SQL Database performance, health, and operational issues using Azure REST APIs and Query Store data.</p> <p>Warning</p> <p>This toolset is in Experimental stage.</p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#prerequisites","title":"Prerequisites","text":"<ol> <li>Azure SQL Database instance</li> <li>Azure authentication (Service Principal or Azure AD Workload Identity)</li> <li>Appropriate Azure and SQL permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/azure-sql/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart"},{"location":"data-sources/builtin-toolsets/azure-sql/#azure-ad-workload-identity","title":"Azure AD Workload Identity","text":"<p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  azure/sql:\n    enabled: true\n    config:\n      database:\n        subscription_id: \"your-subscription-id\"\n        resource_group: \"your-resource-group\"\n        server_name: \"your-azure-sql-server-name\"\n        database_name: \"your-azure-sql-database-name\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#service-principal","title":"Service Principal","text":"<pre><code>toolsets:\n  azure/sql:\n    enabled: true\n    config:\n      tenant_id: \"your-tenant-id\"\n      client_id: \"your-client-id\"\n      client_secret: \"your-client-secret\"\n      database:\n        subscription_id: \"your-subscription-id\"\n        resource_group: \"your-resource-group\"\n        server_name: \"your-azure-sql-server-name\"\n        database_name: \"your-azure-sql-database-name\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#azure-ad-workload-identity_1","title":"Azure AD Workload Identity","text":"<pre><code>holmes:\n  toolsets:\n    azure/sql:\n      enabled: true\n      config:\n        database:\n          subscription_id: \"your-subscription-id\"\n          resource_group: \"your-resource-group\"\n          server_name: \"your-azure-sql-server-name\"\n          database_name: \"your-azure-sql-database-name\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#service-principal_1","title":"Service Principal","text":"<pre><code>holmes:\n  toolsets:\n    azure/sql:\n      enabled: true\n      config:\n        tenant_id: \"your-tenant-id\"\n        client_id: \"your-client-id\"\n        client_secret: \"your-client-secret\"\n        database:\n          subscription_id: \"your-subscription-id\"\n          resource_group: \"your-resource-group\"\n          server_name: \"your-azure-sql-server-name\"\n          database_name: \"your-azure-sql-database-name\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#roles-access-controls","title":"Roles / Access controls","text":"<p>The service principal requires these roles:</p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#azure","title":"Azure","text":"<pre><code>Azure Level (RBAC):\n\u251c\u2500\u2500 Monitoring Reader (subscription)\n\u251c\u2500\u2500 SQL DB Contributor (resource group)\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#sql","title":"SQL","text":"<pre><code>Database Level (SQL permissions):\n\u251c\u2500\u2500 CREATE USER [holmes-service-principal] FROM EXTERNAL PROVIDER\n\u251c\u2500\u2500 GRANT VIEW SERVER STATE TO [holmes-service-principal]\n\u2514\u2500\u2500 ALTER ROLE db_datareader ADD MEMBER [holmes-service-principal]\n</code></pre>"},{"location":"data-sources/builtin-toolsets/azure-sql/#query-store","title":"Query Store","text":"<p>In addition, Query Store should be enabled on target databases</p>"},{"location":"data-sources/builtin-toolsets/azure-sql/#capabilities","title":"Capabilities","text":"Tool Name Description analyze_database_health_status Analyze overall database health and status analyze_database_performance Analyze database performance metrics analyze_database_connections Analyze database connection patterns and issues analyze_database_storage Analyze database storage usage and growth get_top_cpu_queries Get queries with highest CPU usage get_slow_queries Get slowest performing queries get_top_data_io_queries Get queries with highest data I/O usage get_top_log_io_queries Get queries with highest log I/O usage get_active_alerts Get active alerts for the database analyze_connection_failures Analyze connection failure patterns"},{"location":"data-sources/builtin-toolsets/confluence/","title":"Confluence","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch Confluence pages. This is particularly useful if you store runbooks in Confluence and want Holmes to run investigations using these runbooks.</p> <p>This toolset requires an Atlassian API Key.</p>"},{"location":"data-sources/builtin-toolsets/confluence/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Set the following environment variables and the Confluence toolset will be automatically enabled:</p> <pre><code>export CONFLUENCE_USER=\"&lt;Confluence username&gt;\"\nexport CONFLUENCE_API_KEY=\"&lt;Confluence API key&gt;\"\nexport CONFLUENCE_BASE_URL=\"&lt;Confluence base URL&gt;\"\n</code></pre> <p>To test, run:</p> <pre><code>holmes ask \"why is my application failing? Get relevant runbooks from Confluence\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>Helm Values:</p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: CONFLUENCE_USER\n          value: &lt;Confluence username&gt;\n        - name: CONFLUENCE_API_KEY\n          value: &lt;Confluence API key&gt;\n        - name: CONFLUENCE_BASE_URL\n          value: &lt;Confluence base URL&gt;\n    toolsets:\n        confluence:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/confluence/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_confluence_url Fetch a page in Confluence. Use this to fetch Confluence runbooks if they are present before starting your investigation."},{"location":"data-sources/builtin-toolsets/coralogix-logs/","title":"Coralogix logs","text":"<p>By enabling this toolset, HolmesGPT will fetch pod logs from Coralogix.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Grafana Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Coralogix API key which is assigned the <code>DataQuerying</code> permission preset</li> <li>A Coralogix domain. For example <code>eu2.coralogix.com</code></li> <li>Your team's name or hostname. For example <code>your-company-name</code></li> </ol> <p>You can deduce the <code>domain</code> and <code>team_hostname</code> configuration fields by looking at the URL you use to access the Coralogix UI.</p> <p>For example if you access Coralogix at <code>https://my-team.app.eu2.coralogix.com/</code> then the <code>team_hostname</code> is <code>my-team</code> and the Coralogix <code>domain</code> is <code>eu2.coralogix.com</code>.</p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  coralogix/logs:\n    enabled: true\n    config:\n      api_key: \"&lt;your Coralogix API key&gt;\"\n      domain: \"eu2.coralogix.com\"\n      team_hostname: \"your-company-name\"\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    coralogix/logs:\n      enabled: true\n      config:\n        api_key: \"&lt;your Coralogix API key&gt;\"\n        domain: \"eu2.coralogix.com\"\n        team_hostname: \"your-company-name\"\n\n    kubernetes/logs:\n      enabled: false  # Disable default Kubernetes logging\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/coralogix-logs/#capabilities","title":"Capabilities","text":"Tool Name Description coralogix_fetch_logs Fetch logs from Coralogix for specified pods and time ranges"},{"location":"data-sources/builtin-toolsets/datadog/","title":"Datadog","text":"<p>Connect HolmesGPT to Datadog for log analysis and metrics access from your Datadog dashboards.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Grafana Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/datadog/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Datadog API key with log access permissions</li> <li>A Datadog Application key</li> </ol> <p>You can find these in your Datadog account under Organization Settings &gt; API Keys and Application Keys.</p>"},{"location":"data-sources/builtin-toolsets/datadog/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the following environment variables:</p> <pre><code>export DD_API_KEY=\"your-Datadog-api-key\"\nexport DD_APP_KEY=\"your-Datadog-app-key\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  datadog/logs:\n    enabled: true\n    config:\n      site: \"datadoghq.com\"  # or datadoghq.eu for EU, etc.\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  additionalEnvVars:\n    - name: DD_API_KEY\n      value: \"&lt;your Datadog API key&gt;\"\n    - name: DD_APP_KEY\n      value: \"&lt;your Datadog application key&gt;\"\n  toolsets:\n    datadog/logs:\n      enabled: true\n      config:\n        site: \"datadoghq.com\"  # or datadoghq.eu for EU, etc.\n\n    kubernetes/logs:\n      enabled: false  # Disable default Kubernetes logging\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/datadog/#validation","title":"Validation","text":"<p>Test your configuration:</p> <pre><code>holmes ask \"show me recent application errors\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datadog/#capabilities","title":"Capabilities","text":"Tool Name Description datadog_fetch_logs Fetch logs from Datadog for specified time ranges and filters datadog_search_logs Search logs in Datadog using query patterns"},{"location":"data-sources/builtin-toolsets/datetime/","title":"Datetime \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default. You do not need to configure it. You can disable it if you want to but doing so may negatively impact HolmesGPT's ability to investigate issues.</p> <p>By enabling this toolset, HolmesGPT will be able to get the current UTC date and time. This feature should be kept enabled as it can be necessary for other toolsets that rely on dates and time.</p> <p>The following built-in toolsets depend on <code>datetime</code>:</p> <ul> <li>Grafana Loki</li> <li>Prometheus</li> <li>Coralogix logs</li> </ul>"},{"location":"data-sources/builtin-toolsets/datetime/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        datetime:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/datetime/#capabilities","title":"Capabilities","text":"Tool Name Description get_current_time Return current time information. Useful to build queries that require time information"},{"location":"data-sources/builtin-toolsets/docker/","title":"Docker","text":"<p>Not Recommended for Kubernetes</p> <p>This integration is not recommended for monitoring a Kubernetes cluster because it is neither necessary nor useful. It is documented here for users of HolmesGPT CLI.</p> <p>Read access to Docker resources.</p>"},{"location":"data-sources/builtin-toolsets/docker/#configuration","title":"Configuration","text":"Holmes CLI <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    docker/core:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/docker/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description docker_images List all Docker images docker_ps List all running Docker containers docker_ps_all List all Docker containers, including stopped ones docker_inspect Inspect detailed information about a Docker container or image docker_logs Fetch the logs of a Docker container docker_top Display the running processes of a container docker_events Get real-time events from the Docker server docker_history Show the history of an image docker_diff Inspect changes to files or directories on a container's filesystem"},{"location":"data-sources/builtin-toolsets/github/","title":"GitHub","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with GitHub repositories, read files, create pull requests, and manage branches. This is useful for accessing runbooks, documentation, or configuration files stored in GitHub.</p>"},{"location":"data-sources/builtin-toolsets/github/#prerequisites","title":"Prerequisites","text":"<ol> <li>A GitHub Personal Access Token with appropriate permissions:</li> <li><code>repo</code> scope for private repositories</li> <li><code>public_repo</code> scope for public repositories</li> <li><code>pull_requests:write</code> for creating PRs</li> </ol> <p>You can create a token at GitHub Settings &gt; Developer settings &gt; Personal access tokens.</p>"},{"location":"data-sources/builtin-toolsets/github/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the following environment variable:</p> <pre><code>export GITHUB_TOKEN=\"&lt;your GitHub personal access token&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  git/github:\n    enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Check the troubleshooting guide in our GitHub repository for common deployment issues\"\n</code></pre> <pre><code>holmes:\n  additionalEnvVars:\n    - name: GITHUB_TOKEN\n      value: \"&lt;your GitHub personal access token&gt;\"\n  toolsets:\n    git/github:\n      enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/github/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure additional options:</p> <pre><code>toolsets:\n  git/github:\n    enabled: true\n    config:\n      default_branch: \"main\"  # Default branch to use\n      max_file_size: 1048576  # Maximum file size to read (1MB)\n      timeout: 30  # Request timeout in seconds\n</code></pre>"},{"location":"data-sources/builtin-toolsets/github/#capabilities","title":"Capabilities","text":"Tool Name Description github_read_file Read a file from a GitHub repository github_list_files List files in a GitHub repository directory github_search_files Search for files in a repository by name or content github_create_pr Create a new pull request github_update_pr Update an existing pull request github_list_branches List branches in a repository github_create_branch Create a new branch github_get_commit Get details about a specific commit"},{"location":"data-sources/builtin-toolsets/grafanaloki/","title":"Grafana Loki","text":"<p>Connect HolmesGPT to Loki for log analysis through Grafana or direct API access. Provides access to historical logs and advanced log queries.</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#when-to-use-this","title":"When to Use This","text":"<ul> <li>\u2705 Your Kubernetes logs are centralized in Loki</li> <li>\u2705 You need historical log data beyond what's in pods</li> <li>\u2705 You want advanced log search capabilities</li> </ul>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#prerequisites","title":"Prerequisites","text":"<ul> <li>Loki instance with logs from your Kubernetes cluster</li> <li>Grafana with Loki datasource configured (recommended) OR direct Loki API access</li> </ul> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Grafana Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#configuration","title":"Configuration","text":"<p>Choose one of the following methods:</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#option-1-through-grafana-recommended","title":"Option 1: Through Grafana (Recommended)","text":"<p>Required: - Grafana service account token with Viewer role - Loki datasource UID from Grafana</p> <p>Find your Loki datasource UID: <pre><code># Port forward to Grafana\nkubectl port-forward svc/grafana 3000:80\n\n# Get Loki datasource UID\ncurl -s -u admin:admin http://localhost:3000/api/datasources | jq '.[] | select(.type == \"loki\") | .uid'\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#configuration-grafana-proxy","title":"Configuration (Grafana Proxy)","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      api_key: &lt;your grafana API key&gt;\n      url: https://xxxxxxx.grafana.net # Your Grafana cloud account URL\n      grafana_datasource_uid: &lt;the UID of the loki data source in Grafana&gt;\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    grafana/loki:\n      enabled: true\n      config:\n        api_key: &lt;your grafana API key&gt;\n        url: https://xxxxxxx.grafana.net # Your Grafana cloud account URL\n        grafana_datasource_uid: &lt;the UID of the loki data source in Grafana&gt;\n\n    kubernetes/logs:\n      enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#direct-connection","title":"Direct Connection","text":"<p>The toolset can directly connect to a Loki instance without proxying through a Grafana instance. This is done by not setting the <code>grafana_datasource_uid</code> field. Not setting this field makes HolmesGPT assume that it is directly connecting to Loki.</p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#configuration-direct-connection","title":"Configuration (Direct Connection)","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: http://loki.logging\n      headers:\n        X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if loki multitenancy is enabled\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    grafana/loki:\n      enabled: true\n      config:\n        url: http://loki.logging\n        headers:\n          X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if loki multitenancy is enabled\n\n    kubernetes/logs:\n      enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"data-sources/builtin-toolsets/grafanaloki/#search-labels","title":"Search Labels","text":"<p>You can tweak the labels used by the toolset to identify Kubernetes resources. This is only needed if your Loki logs settings for <code>pod</code> and <code>namespace</code> differ from the defaults.</p> Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml:</p> <pre><code>toolsets:\n  grafana/loki:\n    enabled: true\n    config:\n      url: ...\n      labels:\n          pod: \"pod\"\n          namespace: \"namespace\"\n</code></pre> <pre><code>holmes:\n  toolsets:\n    grafana/loki:\n      enabled: true\n      config:\n        url: ...\n        labels:\n            pod: \"pod\"\n            namespace: \"namespace\"\n</code></pre> <p>Use the following commands to list Loki's labels and determine which ones to use:</p> <pre><code># Make Loki accessible locally\nkubectl port-forward svc/loki 3100:3100\n\n# List all labels. You may have to add the -H 'X-Scope-OrgID:&lt;org id&gt;' option with a valid org id\ncurl http://localhost:3100/loki/api/v1/labels\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanaloki/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_pod_logs Fetches pod logs from Loki"},{"location":"data-sources/builtin-toolsets/grafanatempo/","title":"Grafana Tempo","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch trace information from Grafana Tempo to debug performance related issues, like high latency in your application.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#proxying-through-grafana","title":"Proxying through Grafana","text":"<p>This is the recommended approach because we intend to add more capabilities to the toolset that are only available with Grafana.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#prerequisites","title":"Prerequisites","text":"<p>A Grafana service account token with the following permissions:</p> <ul> <li>Basic role -&gt; Viewer</li> <li>Data sources -&gt; Reader</li> </ul> <p>Check out this video on creating a Grafana service account token.</p> <p>Getting Grafana URL</p> <p>You can find the Grafana URL required for Tempo in your Grafana cloud account settings.</p> <p>Obtaining the datasource UID</p> <p>You may have multiple Tempo data sources set up in Grafana. HolmesGPT uses a single Tempo datasource to fetch the traces and it needs to know the UID of this datasource.</p> <p>A simple way to get the datasource UID is to access the Grafana API by running the following request:</p> <pre><code># port forward if you are using Robusta's Grafana from your Kubernetes cluster\nkubectl port-forward svc/robusta-grafana 3000:80\n# List the Tempo data sources\ncurl -s -u &lt;username&gt;:&lt;password&gt; http://localhost:3000/api/datasources | jq '.[] | select(.type == \"tempo\")'\n</code></pre> <p>This will return something like:</p> <pre><code>{\n    \"id\": 3,\n    \"uid\": \"klja8hsa-8a9c-4b35-1230-7baab22b02ee\",\n    \"orgId\": 1,\n    \"name\": \"Tempo\",\n    \"type\": \"tempo\",\n    \"typeName\": \"Tempo\",\n    \"typeLogoUrl\": \"/public/app/plugins/datasource/tempo/img/tempo_icon.svg\",\n    \"access\": \"proxy\",\n    \"url\": \"http://tempo-query-frontend.tempo:3100\",\n    \"user\": \"\",\n    \"database\": \"\",\n    \"basicAuth\": false,\n    \"isDefault\": false,\n    \"jsonData\": {\n        \"tlsSkipVerify\": true\n    },\n    \"readOnly\": false\n}\n</code></pre> <p>In this case, the Tempo datasource UID is <code>klja8hsa-8a9c-4b35-1230-7baab22b02ee</code>.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#configuration-grafana-proxy","title":"Configuration (Grafana Proxy)","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/tempo:\n    enabled: true\n    config:\n      api_key: &lt;your grafana service account token&gt;\n      url: &lt;your grafana url&gt; # e.g. https://acme-corp.grafana.net\n      grafana_datasource_uid: &lt;the UID of the tempo data source in Grafana&gt;\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"The payments DB is very slow, check tempo for any trace data\"\n</code></pre> <pre><code>holmes:\n  toolsets:\n    grafana/tempo:\n      enabled: true\n      config:\n        api_key: &lt;your grafana API key&gt;\n        url: &lt;your grafana url&gt; # e.g. https://acme-corp.grafana.net\n        grafana_datasource_uid: &lt;the UID of the tempo data source in Grafana&gt;\n        labels:\n          pod: \"k8s.pod.name\"\n          namespace: \"k8s.namespace.name\"\n          deployment: \"k8s.deployment.name\"\n          node: \"k8s.node.name\"\n          service: \"service.name\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#direct-connection","title":"Direct Connection","text":"<p>The toolset can directly connect to a Tempo instance without proxying through a Grafana instance. This is done by not setting the <code>grafana_datasource_uid</code> field. Not setting this field makes HolmesGPT assume that it is directly connecting to Tempo.</p>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#configuration-direct-connection","title":"Configuration (Direct Connection)","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  grafana/tempo:\n    enabled: true\n    config:\n      url: http://tempo.monitoring\n      headers:\n        X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if tempo multitenancy is enabled\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    grafana/tempo:\n      enabled: true\n      config:\n        url: http://tempo.monitoring\n        headers:\n          X-Scope-OrgID: \"&lt;tenant id&gt;\" # Set the X-Scope-OrgID if tempo multitenancy is enabled\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"data-sources/builtin-toolsets/grafanatempo/#search-labels","title":"Search Labels","text":"<p>You can tweak the labels used by the toolset to identify Kubernetes resources. This is only needed if the trace labels differ from the defaults.</p> Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml:</p> <pre><code>toolsets:\n  grafana/tempo:\n    enabled: true\n    config:\n      url: ...\n      labels:\n        pod: \"k8s.pod.name\"\n        namespace: \"k8s.namespace.name\"\n        deployment: \"k8s.deployment.name\"\n        node: \"k8s.node.name\"\n        service: \"service.name\"\n</code></pre> <pre><code>holmes:\n  toolsets:\n    grafana/tempo:\n      enabled: true\n      config:\n        url: ...\n        labels:\n          pod: \"k8s.pod.name\"\n          namespace: \"k8s.namespace.name\"\n          deployment: \"k8s.deployment.name\"\n          node: \"k8s.node.name\"\n          service: \"service.name\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/grafanatempo/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_tempo_tags List the tags available in Tempo fetch_tempo_traces Lists Tempo traces. At least one of <code>service_name</code>, <code>pod_name</code>, or <code>deployment_name</code> argument is required. fetch_tempo_trace_by_id Retrieves detailed information about a Tempo trace using its trace ID. Use this to investigate a trace."},{"location":"data-sources/builtin-toolsets/helm/","title":"Helm \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default. You do not need to configure it. You can disable it if you want to but doing so may negatively impact HolmesGPT's ability to investigate issues.</p> <p>By enabling this toolset, HolmesGPT will be able to provide read access to a cluster's Helm charts and releases.</p>"},{"location":"data-sources/builtin-toolsets/helm/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    helm/core:\n        enabled: true\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    toolsets:\n        helm/core:\n            enabled: true\n    customClusterRoleRules:\n        - apiGroups: [\"\"]\n          resources: [\"secrets\", \"pods\", \"services\", \"configmaps\", \"persistentvolumeclaims\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n        - apiGroups: [\"\"]\n          resources: [\"namespaces\"]\n          verbs: [\"get\"]\n        - apiGroups: [\"apps\"]\n          resources: [\"deployments\", \"statefulsets\", \"daemonsets\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n        - apiGroups: [\"batch\"]\n          resources: [\"jobs\", \"cronjobs\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n        - apiGroups: [\"networking.k8s.io\"]\n          resources: [\"ingresses\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/helm/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description helm_list Use to get all the current helm releases helm_values Use to gather Helm values or any released helm chart helm_status Check the status of a Helm release helm_history Get the revision history of a Helm release helm_manifest Fetch the generated Kubernetes manifest for a Helm release helm_hooks Get the hooks for a Helm release helm_chart Show the chart used to create a Helm release helm_notes Show the notes provided by the Helm chart"},{"location":"data-sources/builtin-toolsets/internet/","title":"Internet \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default and should typically remain enabled.</p> <p>By enabling this toolset, HolmesGPT will be able to fetch webpages. This tool is beneficial if you provide Holmes with publicly accessible web-based runbooks.</p>"},{"location":"data-sources/builtin-toolsets/internet/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        internet:\n            enabled: true\n            config: # optional\n              additional_headers:\n                Authorization: Bearer ...\n</code></pre>"},{"location":"data-sources/builtin-toolsets/internet/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_webpage Fetch a webpage. Use this to fetch runbooks if they are present before starting your investigation (if no other tool like Confluence is more appropriate)"},{"location":"data-sources/builtin-toolsets/kafka/","title":"Kafka","text":"<p>By enabling this toolset, HolmesGPT will be able to fetch metadata from Kafka. This provides Holmes the ability to introspect into Kafka by listing consumers and topics or finding lagging consumer groups.</p> <p>This toolset uses the AdminClient of the confluent-kafka python library. Kafka's Java API is also a good source of documentation.</p>"},{"location":"data-sources/builtin-toolsets/kafka/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    kafka/admin:\n        enabled: true\n        config:\n            kafka_clusters:\n                - name: aks-prod-kafka\n                  kafka_broker: kafka-1.aks-prod-kafka-brokers.kafka.svc:9095\n                  kafka_username: kafka-plaintext-user\n                  kafka_password: ******\n                  kafka_sasl_mechanism: SCRAM-SHA-512\n                  kafka_security_protocol: SASL_PLAINTEXT\n                - name: gke-stg-kafka\n                  kafka_broker: gke-kafka.gke-stg-kafka-brokers.kafka.svc:9095\n                  kafka_username: kafka-plaintext-user\n                  kafka_password: ****\n                  kafka_sasl_mechanism: SCRAM-SHA-512\n                  kafka_security_protocol: SASL_PLAINTEXT\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    toolsets:\n        kafka/admin:\n            enabled: true\n            config:\n                kafka_clusters:\n                    - name: aks-prod-kafka\n                      kafka_broker: kafka-1.aks-prod-kafka-brokers.kafka.svc:9095\n                      kafka_username: kafka-plaintext-user\n                      kafka_password: ******\n                      kafka_sasl_mechanism: SCRAM-SHA-512\n                      kafka_security_protocol: SASL_PLAINTEXT\n                    - name: gke-stg-kafka\n                      kafka_broker: gke-kafka.gke-stg-kafka-brokers.kafka.svc:9095\n                      kafka_username: kafka-plaintext-user\n                      kafka_password: ****\n                      kafka_sasl_mechanism: SCRAM-SHA-512\n                      kafka_security_protocol: SASL_PLAINTEXT\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>Below is a description of the configuration field for each cluster:</p> Config key Description name Give a meaningful name to your cluster. Holmes will use it to decide what cluster to look into. Names must be unique across all clusters. kafka_broker List of host/port pairs to use for establishing the initial connection to the Kafka cluster kafka_username Username for SASL authentication kafka_password Password for SASL authentication kafka_sasl_mechanism SASL mechanism (e.g., SCRAM-SHA-512) kafka_security_protocol Security protocol (e.g., SASL_PLAINTEXT)"},{"location":"data-sources/builtin-toolsets/kafka/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description kafka_list_topics List all Kafka topics kafka_describe_topic Get detailed information about a specific topic kafka_list_consumers List all consumer groups kafka_describe_consumer Get detailed information about a consumer group kafka_consumer_lag Check consumer lag for a consumer group"},{"location":"data-sources/builtin-toolsets/kubernetes/","title":"Kubernetes Toolsets","text":""},{"location":"data-sources/builtin-toolsets/kubernetes/#core","title":"Core \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default and should typically remain enabled.</p> <p>By enabling this toolset, HolmesGPT will be able to describe and find Kubernetes resources like nodes, deployments, pods, etc.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/core:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities","title":"Capabilities","text":"Tool Name Description kubectl_describe Run kubectl describe command on a specific resource kubectl_get_by_name Get details of a specific resource with labels kubectl_get_by_kind_in_namespace List all resources of a given type in a namespace kubectl_get_by_kind_in_cluster List all resources of a given type across the cluster kubectl_find_resources Search for resources matching a keyword kubectl_get_yaml Get YAML definition of a resource kubectl_events Get events for a specific resource kubectl_memory_requests_all_namespaces Get memory requests for all pods across all namespaces in MiB kubectl_memory_requests_namespace Get memory requests for all pods in a specific namespace in MiB kubernetes_jq_query Query Kubernetes resources using jq filters"},{"location":"data-sources/builtin-toolsets/kubernetes/#logs","title":"Logs \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default. You do not need to configure it.</p> <p>By enabling this toolset, HolmesGPT will be able to read Kubernetes pod logs.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Grafana Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_1","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/logs:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_1","title":"Capabilities","text":"Tool Name Description kubectl_logs Fetch logs from a specific pod kubectl_logs_all_containers Fetch logs from all containers in a pod kubectl_previous_logs Fetch previous logs from a pod kubectl_previous_logs_all_containers Fetch previous logs from all containers in a pod kubectl_container_logs Fetch logs from a specific container in a pod kubectl_logs_grep Search for specific patterns in pod logs kubectl_logs_all_containers_grep Search for patterns in logs from all containers"},{"location":"data-sources/builtin-toolsets/kubernetes/#live-metrics","title":"Live Metrics","text":"<p>This toolset retrieves real-time CPU and memory usage for pods and nodes.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_2","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/live_metrics:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_2","title":"Capabilities","text":"Tool Name Description kubectl_top_pods Get current CPU and memory usage for pods kubectl_top_nodes Get current CPU and memory usage for nodes"},{"location":"data-sources/builtin-toolsets/kubernetes/#prometheus-stack","title":"Prometheus Stack","text":"<p>This toolset fetches Prometheus target definitions. Requires specific cluster role rules.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_3","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/prometheus_stack:\n            enabled: true\n    customClusterRoleRules:\n        - apiGroups: [\"monitoring.coreos.com\"]\n          resources: [\"servicemonitors\", \"podmonitors\", \"prometheusrules\"]\n          verbs: [\"get\", \"list\"]\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_3","title":"Capabilities","text":"Tool Name Description kubectl_get_prometheus_targets Get Prometheus monitoring targets kubectl_get_service_monitors Get ServiceMonitor resources kubectl_get_pod_monitors Get PodMonitor resources"},{"location":"data-sources/builtin-toolsets/kubernetes/#resource-lineage-extras","title":"Resource Lineage Extras","text":"<p>Two variations of resource lineage toolsets: one native and one using kubectl krew. Provides tools to fetch children/dependents and parents/dependencies of Kubernetes resources.</p>"},{"location":"data-sources/builtin-toolsets/kubernetes/#configuration_4","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        kubernetes/resource_lineage_extras:\n            enabled: true\n        # OR\n        kubernetes/resource_lineage_extras_krew:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/kubernetes/#capabilities_4","title":"Capabilities","text":"Tool Name Description kubectl_lineage_children Get child/dependent resources of a Kubernetes resource kubectl_lineage_parents Get parent/dependency resources of a Kubernetes resource"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/","title":"MongoDB Atlas","text":"<p>By enabling this toolset, HolmesGPT can access MongoDB Atlas projects and processes to analyze logs, alerts, events, slow queries, and various metrics to understand the state of MongoDB projects.</p> <p>Warning</p> <p>This toolset is in Experimental stage.</p>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#prerequisites","title":"Prerequisites","text":"<ol> <li>MongoDB Atlas account</li> <li>MongoDB Atlas API keys (Public and Private)</li> <li>MongoDB Atlas project ID</li> <li>Appropriate MongoDB Atlas permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the following environment variables:</p> <pre><code>export MONGODB_ATLAS_PUBLIC_KEY=\"&lt;your-public-api-key&gt;\"\nexport MONGODB_ATLAS_PRIVATE_KEY=\"&lt;your-private-api-key&gt;\"\nexport MONGODB_ATLAS_PROJECT_ID=\"&lt;your-project-id&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  MongoDBAtlas:\n    enabled: true\n    config:\n      public_key: \"&lt;your-public-api-key&gt;\"\n      private_key: \"&lt;your-private-api-key&gt;\"\n      project_id: \"&lt;your-project-id&gt;\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  additionalEnvVars:\n    - name: MONGODB_ATLAS_PUBLIC_KEY\n      value: \"&lt;your-public-api-key&gt;\"\n    - name: MONGODB_ATLAS_PRIVATE_KEY\n      value: \"&lt;your-private-api-key&gt;\"\n    - name: MONGODB_ATLAS_PROJECT_ID\n      value: \"&lt;your-project-id&gt;\"\n  toolsets:\n    MongoDBAtlas:\n      enabled: true\n      config:\n        public_key: \"&lt;your-public-api-key&gt;\"\n        private_key: \"&lt;your-private-api-key&gt;\"\n        project_id: \"&lt;your-project-id&gt;\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#setting-up-mongodb-atlas-api-keys","title":"Setting up MongoDB Atlas API Keys","text":"<ol> <li>Log into MongoDB Atlas and navigate to your organization</li> <li>Go to Access Manager \u2192 API Keys</li> <li>Create a new API key:</li> <li>Set appropriate permissions for your use case</li> <li>Copy the public key and private key</li> <li>Get your Project ID:</li> <li>Navigate to your project</li> <li>Copy the Project ID from the project settings</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#required-permissions","title":"Required Permissions","text":"<p>The API key requires the following permissions:</p> <ul> <li>Project Read Only - To read project information</li> <li>Project Data Access Admin - To access database logs and metrics</li> <li>Project Monitoring Admin - To access monitoring data and alerts</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#capabilities","title":"Capabilities","text":"Tool Name Description atlas_return_project_alerts Get alerts for the MongoDB Atlas project atlas_return_project_processes Get information about processes in the project atlas_return_project_slow_queries Get slow queries from the project (last 24 hours) atlas_return_events_from_project Get events from the project (last 24 hours) atlas_return_logs_for_host_in_project Get logs for a specific host in the project atlas_return_event_type_from_project Get events of a specific type from the project"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#usage-guidelines","title":"Usage Guidelines","text":""},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#performance-analysis","title":"Performance Analysis","text":"<p>When investigating performance issues:</p> <ol> <li>Start with alerts and events: Use <code>atlas_return_project_alerts</code> and <code>atlas_return_events_from_project</code> first to identify known issues</li> <li>Check slow queries: Use <code>atlas_return_project_slow_queries</code> to identify performance bottlenecks</li> <li>Review logs: Use <code>atlas_return_logs_for_host_in_project</code> for detailed log analysis</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#time-range-limitations","title":"Time Range Limitations","text":"<ul> <li><code>atlas_return_project_slow_queries</code> returns data from the last 24 hours only</li> <li><code>atlas_return_events_from_project</code> returns data from the last 24 hours only</li> <li>If you need data from a different time range, the toolset will inform you it's not currently supported</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#query-analysis","title":"Query Analysis","text":"<ul> <li>When analyzing slow queries, the toolset will show the actual query text for every slow query</li> <li>For requests asking for a specific number of slow queries (e.g., \"top 10 slow queries\"), the toolset will not duplicate queries from different processes</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#common-issues","title":"Common Issues","text":"<ol> <li>Authentication Failures</li> <li>Verify your API keys are correct</li> <li>Check that the API key has appropriate permissions</li> <li> <p>Ensure the project ID is correct</p> </li> <li> <p>Permission Errors</p> </li> <li>Verify the API key has the required permissions listed above</li> <li> <p>Check that the key is associated with the correct organization</p> </li> <li> <p>No Data Returned</p> </li> <li>Verify the project ID is correct</li> <li>Check that there are active processes in the project</li> <li>Ensure the time range contains relevant data</li> </ol>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#api-rate-limits","title":"API Rate Limits","text":"<p>MongoDB Atlas API has rate limits. If you encounter rate limiting:</p> <ul> <li>Wait before making additional requests</li> <li>Consider the frequency of your queries</li> <li>Check MongoDB Atlas documentation for current rate limits</li> </ul>"},{"location":"data-sources/builtin-toolsets/mongodb-atlas/#references","title":"References","text":"<ul> <li>MongoDB Atlas API Documentation</li> <li>MongoDB Atlas API Authentication</li> <li>MongoDB Atlas Monitoring</li> </ul>"},{"location":"data-sources/builtin-toolsets/newrelic/","title":"New Relic","text":"<p>By enabling this toolset, HolmesGPT will be able to pull traces and logs from New Relic for investigations.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Grafana Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/newrelic/#prerequisites","title":"Prerequisites","text":"<ol> <li>A New Relic API Key with necessary permissions to access traces and logs</li> <li>Your New Relic Account ID</li> </ol> <p>You can find these in your New Relic account under Administration &gt; API keys and Account settings.</p>"},{"location":"data-sources/builtin-toolsets/newrelic/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  newrelic:\n    enabled: true\n    config:\n      nr_api_key: \"&lt;your New Relic API key&gt;\"\n      nr_account_id: \"&lt;your New Relic account ID&gt;\"\n\n  kubernetes/logs:\n    enabled: false  # Disable default Kubernetes logging if using New Relic for logs\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    newrelic:\n      enabled: true\n      config:\n        nr_api_key: \"&lt;your New Relic API key&gt;\"\n        nr_account_id: \"&lt;your New Relic account ID&gt;\"\n\n    kubernetes/logs:\n      enabled: false  # Disable default Kubernetes logging if using New Relic for logs\n</code></pre> <p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p>"},{"location":"data-sources/builtin-toolsets/newrelic/#capabilities","title":"Capabilities","text":"Tool Name Description <p>| <code>newrelic_get_logs</code> | Retrieve logs from New Relic for a specific application and time range | | <code>newrelic_get_traces</code> | Retrieve traces from New Relic based on duration threshold or specific trace ID |</p> <p>For more information, see the New Relic API documentation.</p>"},{"location":"data-sources/builtin-toolsets/notion/","title":"Notion","text":"<p>Notion Integration for HolmesGPT</p> <p>Enabling this toolset allows HolmesGPT to fetch pages from Notion, making it useful when providing Notion-based runbooks.</p>"},{"location":"data-sources/builtin-toolsets/notion/#setup-instructions","title":"Setup Instructions","text":"<ol> <li> <p>Create a Webhook Integration</p> <ul> <li>Go to the Notion Developer Portal.</li> <li>Create a new integration with read content capabilities.</li> </ul> </li> <li> <p>Grant Access to Pages</p> <ul> <li>Open the desired Notion page.</li> <li>Click the three dots in the top right.</li> <li>Select Connections and add your integration.</li> </ul> </li> <li> <p>Configure Authentication</p> <ul> <li>Retrieve the Internal Integration Secret from Notion.</li> <li>Create a Kubernetes secret in your cluster with this key.</li> <li>Configure the <code>NOTION_AUTH</code> environment variable.</li> </ul> </li> </ol>"},{"location":"data-sources/builtin-toolsets/notion/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the environment variable: <pre><code>export NOTION_AUTH=\"&lt;your Notion integration secret&gt;\"\n</code></pre></p> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist: <pre><code>toolsets:\n    notion:\n        enabled: true\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: NOTION_AUTH\n          value: \"&lt;your Notion integration secret&gt;\"\n    toolsets:\n        notion:\n            enabled: true\n            config:\n                additional_headers:\n                    Authorization: Bearer {{ env.NOTION_AUTH }}\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/notion/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description fetch_notion_webpage Fetch a Notion webpage. Use this to fetch Notion runbooks if they are present before starting your investigation"},{"location":"data-sources/builtin-toolsets/opensearch-logs/","title":"OpenSearch Logs","text":"<p>By enabling this toolset, HolmesGPT will fetch pod logs from OpenSearch.</p> Important: Disable Default Logging Toolset <p>Only one logging toolset should be enabled at a time. If you enable this toolset, disable the default <code>kubernetes/logs</code> toolset.</p> <p>Available Log Sources:</p> <ul> <li>Kubernetes logs - Direct pod log access (enabled by default)</li> <li>Grafana Loki - Centralized logs via Loki</li> <li>OpenSearch logs - Logs from OpenSearch/Elasticsearch</li> <li>Coralogix logs - Logs via Coralogix platform</li> <li>DataDog - Logs from DataDog</li> </ul> <p>\ud83d\udca1 Choose one: Only enable one logging toolset at a time for best performance.</p>"},{"location":"data-sources/builtin-toolsets/opensearch-logs/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml, creating the file if it doesn't exist:</p> <pre><code>toolsets:\n  opensearch/logs:\n    enabled: true\n    config:\n      opensearch_url: &lt;your opensearch/elastic URL&gt;\n      index_pattern: &lt;name of the index to use&gt; # The pattern matching the indexes containing the logs. Supports wildcards. For example `fluentd-*`\n      opensearch_auth_header: \"ApiKey &lt;...&gt;\" # An optional header value set to the `Authorization` header for every request to opensearch\n      labels: # set the labels according to how values are mapped in your opensearch cluster\n        pod: \"kubernetes.pod_name\"\n        namespace: \"kubernetes.namespace_name\"\n        timestamp: \"@timestamp\"\n        message: \"message\"\n\n  kubernetes/logs:\n    enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n  toolsets:\n    opensearch/logs:\n      enabled: true\n      config:\n        opensearch_url: https://skdjasid.europe-west1.gcp.cloud.es.io:443 # The URL to your opensearch cluster.\n        index_pattern: fluentd-* # The pattern matching the indexes containing the logs. Supports wildcards\n        opensearch_auth_header: \"ApiKey b0ZlwQWEsdwAkv047bafirkallDFWJIWDWdwlQQ==\" # An optional header value set to the `Authorization` header for every request to opensearch.\n        labels: # set the labels according to how values are mapped in your opensearch cluster\n          pod: \"kubernetes.pod_name\"\n          namespace: \"kubernetes.namespace_name\"\n          timestamp: \"@timestamp\"\n          message: \"message\"\n\n    kubernetes/logs:\n      enabled: false # HolmesGPT's default logging mechanism MUST be disabled\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/opensearch-logs/#configuring-index_pattern-and-labels","title":"Configuring index_pattern and labels","text":"<p>You can tweak the labels used by the toolset to identify kubernetes resources. This is optional and only needed if your logs settings differ from the defaults in the example below.</p> <pre><code>toolsets:\n  opensearch/logs:\n    enabled: true\n    config:\n      index_pattern: fluentd-*\n      labels:\n        pod: \"kubernetes.pod_name\"\n        namespace: \"kubernetes.namespace_name\"\n        timestamp: \"@timestamp\"\n        message: \"message\"\n</code></pre> <p>Below is a screenshot of a query that was done using Elastic dev tools to find out what should be the values for the labels.</p> <p></p> <p>In the image above, the following values and labels are identified by a yellow rectangle:</p> Configuration field Value Description index_pattern fluentd-* This defines what opensearch indexes should be used to fetch logs pod kubernetes.pod_name The kubernetes pod name namespace kubernetes.namespace_name The kubernetes namespace timestamp @timestamp This timestamp is used to search logs by time range. message message This is the content of the log message"},{"location":"data-sources/builtin-toolsets/opensearch-logs/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_pod_logs Retrieve logs using opensearch"},{"location":"data-sources/builtin-toolsets/opensearch-status/","title":"OpenSearch status","text":"<p>By enabling this toolset, HolmesGPT will be able to access cluster metadata information like health, shards, and settings. This allows HolmesGPT to better troubleshoot problems with one or more OpenSearch clusters.</p>"},{"location":"data-sources/builtin-toolsets/opensearch-status/#configuration","title":"Configuration","text":"<p>The configuration for OpenSearch is passed through to the underlying opensearch-py library. Consult this library's user guide or reference documentation for configuring the connection to OpenSearch, including how to authenticate this toolset to an OpenSearch cluster.</p> Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist: <pre><code>toolsets:\n    opensearch/status:\n        enabled: true\n        config:\n            opensearch_clusters:\n                - hosts:\n                    - host1.com\n                    - host2.com\n                  headers:\n                    header1: \"value1\"\n                  use_ssl: &lt;boolean&gt;\n                  ssl_assert_hostname: &lt;boolean&gt;\n                  verify_certs: &lt;boolean&gt;\n                  ssl_show_warn: &lt;boolean&gt;\n                  http_auth:\n                    username: &lt;basic auth username&gt;\n                    password: &lt;basic auth password&gt;\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <p><pre><code>holmes:\n    toolsets:\n        opensearch/status:\n            enabled: true\n            config:\n                opensearch_clusters:\n                    - hosts:\n                        - host1.com\n                        - host2.com\n                      headers:\n                        header1: \"value1\"\n                      use_ssl: &lt;boolean&gt;\n                      ssl_assert_hostname: &lt;boolean&gt;\n                      verify_certs: &lt;boolean&gt;\n                      ssl_show_warn: &lt;boolean&gt;\n                      http_auth:\n                        username: &lt;basic auth username&gt;\n                        password: &lt;basic auth password&gt;\n</code></pre> Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>Here is an example of an insecure OpenSearch configuration for local development using a bearer token:</p> Holmes CLIRobusta Helm Chart <p>First, set the environment variables: <pre><code>export OPENSEARCH_URL=\"&lt;opensearch host URL&gt;\"\nexport OPENSEARCH_BEARER_TOKEN=\"&lt;secret bearer token&gt;\"\n</code></pre></p> <p>Then add the following to ~/.holmes/config.yaml: <pre><code>toolsets:\n    opensearch/status:\n        enabled: true\n        config:\n            opensearch_clusters:\n                - hosts:\n                    - host: \"{{ env.OPENSEARCH_URL }}\"\n                      port: 9200\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: OPENSEARCH_URL\n          value: \"&lt;opensearch host URL&gt;\"\n        - name: OPENSEARCH_BEARER_TOKEN\n          value: \"&lt;secret bearer token&gt;\"\n    toolsets:\n        opensearch/status:\n            enabled: true\n            config:\n                opensearch_clusters:\n                    - hosts:\n                        - host: \"{{ env.OPENSEARCH_URL }}\"\n                          port: 9200\n</code></pre>"},{"location":"data-sources/builtin-toolsets/opensearch-status/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description opensearch_cluster_health Get cluster health information opensearch_cluster_stats Get cluster statistics opensearch_node_info Get information about cluster nodes opensearch_index_stats Get statistics for specific indices opensearch_shard_allocation Get shard allocation information"},{"location":"data-sources/builtin-toolsets/prometheus/","title":"Prometheus","text":"<p>Connect HolmesGPT to Prometheus for metrics analysis and query generation. This integration enables detection of memory leaks, CPU throttling, queue backlogs, and performance issues.</p>"},{"location":"data-sources/builtin-toolsets/prometheus/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running and accessible Prometheus server</li> <li>Ensure HolmesGPT can connect to the Prometheus endpoint</li> </ul>"},{"location":"data-sources/builtin-toolsets/prometheus/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n    prometheus/metrics:\n        enabled: true\n        config:\n            prometheus_url: http://prometheus-server:9090 # localhost:9090 if port-forwarded\n\n            # Optional:\n            #headers:\n            #    Authorization: \"Basic &lt;base_64_encoded_string&gt;\"\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    toolsets:\n        prometheus/metrics:\n            enabled: true\n            config:\n                prometheus_url: http://&lt;your-prometheus-service&gt;:9090\n\n                # Optional:\n                #headers:\n                #    Authorization: \"Basic &lt;base_64_encoded_string&gt;\"\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>\ud83d\udca1 Alternative: Set the <code>PROMETHEUS_URL</code> environment variable instead of using the config file.</p>"},{"location":"data-sources/builtin-toolsets/prometheus/#validation","title":"Validation","text":"<p>To test your connection, run:</p> <pre><code>holmes ask \"Show me the CPU usage for the last hour\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/prometheus/#troubleshooting","title":"Troubleshooting","text":""},{"location":"data-sources/builtin-toolsets/prometheus/#finding-your-prometheus-url","title":"Finding your Prometheus URL","text":"<p>There are several ways to find your Prometheus URL:</p> <p>Option 1: Simple method (port-forwarding)</p> <pre><code># Find Prometheus services\nkubectl get svc -A | grep prometheus\n\n# Port forward for testing\nkubectl port-forward svc/&lt;your-prometheus-service&gt; 9090:9090 -n &lt;namespace&gt;\n# Then access Prometheus at: http://localhost:9090\n</code></pre> <p>Option 2: Advanced method (get full cluster DNS URL)</p> <p>If you want to find the full internal DNS URL for Prometheus, run:</p> <pre><code>kubectl get svc --all-namespaces -o jsonpath='{range .items[*]}{.metadata.name}{\".\"}{.metadata.namespace}{\".svc.cluster.local:\"}{.spec.ports[0].port}{\"\\n\"}{end}' | grep prometheus | grep -Ev 'operat|alertmanager|node|coredns|kubelet|kube-scheduler|etcd|controller' | awk '{print \"http://\"$1}'\n</code></pre> <p>This will print all possible Prometheus service URLs in your cluster. Pick the one that matches your deployment.</p>"},{"location":"data-sources/builtin-toolsets/prometheus/#common-issues","title":"Common Issues","text":"<ul> <li>Connection refused: Check if the Prometheus URL is accessible from HolmesGPT.</li> <li>Authentication errors: Verify the headers configuration for secured Prometheus endpoints.</li> <li>No metrics returned: Ensure that Prometheus is scraping your targets.</li> </ul>"},{"location":"data-sources/builtin-toolsets/prometheus/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can further customize the Prometheus toolset with the following options:</p> <pre><code>toolsets:\n  prometheus/metrics:\n    enabled: true\n    config:\n      prometheus_url: http://&lt;prometheus-host&gt;:9090\n      healthcheck: \"-/healthy\"  # Path for health checking (default: -/healthy)\n      headers:\n        Authorization: \"Basic &lt;base_64_encoded_string&gt;\"\n      metrics_labels_time_window_hrs: 48  # Time window (hours) for fetching labels (default: 48)\n      metrics_labels_cache_duration_hrs: 12  # How long to cache labels (hours, default: 12)\n      fetch_labels_with_labels_api: false  # Use labels API instead of series API (default: false)\n      fetch_metadata_with_series_api: false  # Use series API for metadata (default: false)\n      tool_calls_return_data: true  # If false, disables returning Prometheus data (default: true)\n</code></pre> <p>Config option explanations:</p> <ul> <li><code>prometheus_url</code>: The base URL for Prometheus. Should include protocol and port.</li> <li><code>healthcheck</code>: Path used for health checking Prometheus or Mimir/Cortex endpoint. Defaults to <code>-/healthy</code> for Prometheus, use <code>/ready</code> for Grafana Mimir.</li> <li><code>headers</code>: Extra headers for all Prometheus HTTP requests (e.g., for authentication).</li> <li><code>metrics_labels_time_window_hrs</code>: Time window (in hours) for fetching labels. Set to <code>null</code> to fetch all labels.</li> <li><code>metrics_labels_cache_duration_hrs</code>: How long to cache labels (in hours). Set to <code>null</code> to disable caching.</li> <li><code>fetch_labels_with_labels_api</code>: Use the Prometheus labels API to fetch labels (can improve performance, but increases HTTP calls).</li> <li><code>fetch_metadata_with_series_api</code>: Use the series API for metadata (only set to true if the metadata API is disabled or not working).</li> <li><code>tool_calls_return_data</code>: If <code>false</code>, disables returning Prometheus data to HolmesGPT (useful if you hit token limits).</li> </ul>"},{"location":"data-sources/builtin-toolsets/prometheus/#coralogix-prometheus-configuration","title":"Coralogix Prometheus Configuration","text":"<p>To use a Coralogix PromQL endpoint with HolmesGPT:</p> <ol> <li>Go to Coralogix Documentation and choose the relevant PromQL endpoint for your region.</li> <li>In Coralogix, create an API key with permissions to query metrics (Data Flow \u2192 API Keys).</li> <li> <p>Create a Kubernetes secret for the API key and expose it as an environment variable in your Helm values:</p> <pre><code>holmes:\n  additionalEnvVars:\n    - name: CORALOGIX_API_KEY\n      valueFrom:\n        secretKeyRef:\n          name: coralogix-api-key\n          key: CORALOGIX_API_KEY\n</code></pre> </li> <li> <p>Add the following under your toolsets in the Helm chart:</p> <pre><code>holmes:\n  toolsets:\n    prometheus/metrics:\n      enabled: true\n      config:\n        healthcheck: \"/api/v1/query?query=up\"  # This is important for Coralogix\n        prometheus_url: \"https://prom-api.eu2.coralogix.com\"  # Use your region's endpoint\n        headers:\n          token: \"{{ env.CORALOGIX_API_KEY }}\"\n        metrics_labels_time_window_hrs: 72\n        metrics_labels_cache_duration_hrs: 12\n        fetch_labels_with_labels_api: true\n        tool_calls_return_data: true\n        fetch_metadata_with_series_api: true\n</code></pre> </li> </ol>"},{"location":"data-sources/builtin-toolsets/prometheus/#capabilities","title":"Capabilities","text":"Tool Name Description list_available_metrics List all available Prometheus metrics execute_prometheus_instant_query Execute an instant PromQL query execute_prometheus_range_query Execute a range PromQL query for time series data get_current_time Get current timestamp for time-based queries"},{"location":"data-sources/builtin-toolsets/rabbitmq/","title":"RabbitMQ","text":"<p>By enabling this toolset, HolmesGPT will be able to detect RabbitMQ partitions, memory alerts, and disk alerts and suggest mitigations.</p> <p>This toolset follows a two-step process to detect partition:</p> <ol> <li>The nodes and partitioning status is obtained by fetching information from the configured <code>management_url</code>.</li> <li>If some nodes are reported as not-running, the toolset will try to contact these nodes individually and deduce any partitioning state for any node that is actually running.</li> </ol>"},{"location":"data-sources/builtin-toolsets/rabbitmq/#configuration","title":"Configuration","text":"Robusta Helm ChartHolmes CLI <pre><code>holmes:\n  toolsets:\n    rabbitmq/core:\n      enabled: true\n      config:\n        clusters:\n          - id: rabbitmq # must be unique across all configured clusters\n            username: &lt;user&gt;\n            password: &lt;password&gt;\n            management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>Add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  rabbitmq/core:\n    enabled: true\n    config:\n      clusters:\n        - id: rabbitmq # must be unique across all configured clusters\n          username: &lt;user&gt;\n          password: &lt;password&gt;\n          management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/rabbitmq/#advanced-configuration","title":"Advanced configuration","text":"<p>Below is the full list of options for this toolset:</p> <pre><code>rabbitmq/core:\n  enabled: true\n  config:\n    clusters:\n      - id: rabbitmq # must be unique across all configured clusters\n        username: &lt;user&gt;\n        password: &lt;password&gt;\n        management_url: &lt;http://rabbitmq.rabbitmq:15672&gt;\n        request_timeout_seconds: 30 # timeout for HTTP requests\n</code></pre>"},{"location":"data-sources/builtin-toolsets/rabbitmq/#capabilities","title":"Capabilities","text":"Tool Name Description get_rabbitmq_cluster_status Get cluster status and partition information get_rabbitmq_node_info Get detailed information about RabbitMQ nodes get_rabbitmq_queue_info Get information about queues get_rabbitmq_exchange_info Get information about exchanges get_rabbitmq_memory_usage Get memory usage statistics get_rabbitmq_disk_usage Get disk usage statistics"},{"location":"data-sources/builtin-toolsets/robusta/","title":"Robusta \u2713","text":"<p>Enabled by Default</p> <p>This toolset is enabled by default and should typically remain enabled.</p> <p>By enabling this toolset, HolmesGPT will be able to fetch alerts metadata. It allows HolmesGPT to fetch information about specific issues when chatting using \"Ask HolmesGPT\". This toolset is not necessary for Root Cause Analysis.</p>"},{"location":"data-sources/builtin-toolsets/robusta/#configuration","title":"Configuration","text":"<pre><code>holmes:\n    toolsets:\n        robusta:\n            enabled: true\n</code></pre>"},{"location":"data-sources/builtin-toolsets/robusta/#capabilities","title":"Capabilities","text":"Tool Name Description fetch_finding_by_id Fetches a Robusta finding. Findings are events, like a Prometheus alert or a deployment update"},{"location":"data-sources/builtin-toolsets/servicenow/","title":"ServiceNow","text":"<p>By enabling this toolset, HolmesGPT will be able to interact with ServiceNow for ticket management, incident tracking, and accessing knowledge base articles during investigations.</p> <p>Warning</p> <p>This toolset is in Experimental stage.</p>"},{"location":"data-sources/builtin-toolsets/servicenow/#prerequisites","title":"Prerequisites","text":"<ol> <li>ServiceNow instance URL</li> <li>ServiceNow API key or username and password</li> <li>Appropriate ServiceNow roles and permissions</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#setting-up-servicenow-api-access","title":"Setting up ServiceNow API Access","text":"<p>Full configuration guide</p>"},{"location":"data-sources/builtin-toolsets/servicenow/#create-an-inbound-authentication-profile","title":"Create an inbound authentication profile","text":"<ol> <li>Navigate to All &gt; System Web Services &gt; API Access Policies &gt; Inbound Authentication Profiles</li> <li>Select New</li> <li>Select Create API Key authentication profiles</li> <li>Auth Parameter &gt; add x-sn-apikey: Auth Header</li> <li>Submit the form</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#create-a-rest-api-key","title":"Create a REST API key","text":"<ol> <li>Navigate to All &gt; System Web Services &gt; API Access Policies &gt; REST API Key</li> <li>Select New</li> <li>Set name, description, and user. Set expiry date if desired. &gt; Submit</li> <li>Open the record that was created to view the token generated by the ServiceNow AI Platform for the user</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#create-a-rest-api-access-policy","title":"Create a REST API Access policy","text":"<ol> <li>Navigate to All &gt; System Web Services &gt; REST API Access Policies</li> <li>Select New</li> <li>REST API = Table API</li> <li>Uncheck Apply to all tables &gt; Select table &gt; change_request</li> <li>In select profile from step 1 (API Key)</li> </ol>"},{"location":"data-sources/builtin-toolsets/servicenow/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart"},{"location":"data-sources/builtin-toolsets/servicenow/#api-key-authentication-recommended","title":"API Key Authentication (Recommended)","text":"<p>First, set the following environment variables:</p> <pre><code>export SERVICENOW_INSTANCE=\"&lt;your servicenow instance name&gt;\"  # e.g., \"dev12345\"\nexport SERVICENOW_API_KEY=\"&lt;your servicenow api key&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  servicenow/tickets:\n    enabled: true\n    config:\n      api_key: \"&lt;your servicenow api key&gt;\"\n      instance: \"&lt;your servicenow instance name&gt;\"\n      verify_ssl: true\n      timeout: 30\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/servicenow/#usernamepassword-authentication","title":"Username/Password Authentication","text":"<p>First, set the following environment variables:</p> <pre><code>export SERVICENOW_INSTANCE=\"&lt;your servicenow instance url&gt;\"\nexport SERVICENOW_USERNAME=\"&lt;your servicenow username&gt;\"\nexport SERVICENOW_PASSWORD=\"&lt;your servicenow password&gt;\"\n</code></pre> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist:</p> <pre><code>toolsets:\n  servicenow/tickets:\n    enabled: true\n    config:\n      verify_ssl: true\n      timeout: 30\n</code></pre> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p>"},{"location":"data-sources/builtin-toolsets/servicenow/#api-key-authentication-recommended_1","title":"API Key Authentication (Recommended)","text":"<pre><code>holmes:\n  additionalEnvVars:\n    - name: SERVICENOW_INSTANCE\n      value: \"&lt;your servicenow instance name&gt;\"\n    - name: SERVICENOW_API_KEY\n      value: \"&lt;your servicenow api key&gt;\"\n  toolsets:\n    servicenow/tickets:\n      enabled: true\n      config:\n        api_key: \"&lt;your servicenow api key&gt;\"\n        instance: \"&lt;your servicenow instance name&gt;\"\n        verify_ssl: true\n        timeout: 30\n</code></pre>"},{"location":"data-sources/builtin-toolsets/servicenow/#usernamepassword-authentication_1","title":"Username/Password Authentication","text":"<pre><code>holmes:\n  additionalEnvVars:\n    - name: SERVICENOW_INSTANCE\n      value: \"&lt;your servicenow instance url&gt;\"\n    - name: SERVICENOW_USERNAME\n      value: \"&lt;your servicenow username&gt;\"\n    - name: SERVICENOW_PASSWORD\n      value: \"&lt;your servicenow password&gt;\"\n  toolsets:\n    servicenow/tickets:\n      enabled: true\n      config:\n        verify_ssl: true\n        timeout: 30\n</code></pre>"},{"location":"data-sources/builtin-toolsets/servicenow/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can customize ServiceNow integration settings:</p> <pre><code>toolsets:\n  servicenow/tickets:\n    enabled: true\n    config:\n      verify_ssl: true\n      timeout: 30  # Request timeout in seconds\n      max_results: 100  # Maximum number of tickets to fetch\n      default_table: \"incident\"  # Default ServiceNow table to query\n</code></pre>"},{"location":"data-sources/builtin-toolsets/servicenow/#capabilities","title":"Capabilities","text":"Tool Name Description servicenow_create_incident Create a new incident ticket in ServiceNow servicenow_get_incident Get details of a specific incident servicenow_search_incidents Search for incidents based on criteria servicenow_update_incident Update an existing incident servicenow_get_knowledge_base Search ServiceNow knowledge base articles servicenow_create_change_request Create a change request ticket"},{"location":"data-sources/builtin-toolsets/slab/","title":"Slab","text":"<p>By enabling this toolset, HolmesGPT will be able to consult runbooks from Slab pages.</p> <p>Retrieve your Slab API token prior to configuring this toolset. Do note that Slab API is only available for Slab premium users. See here.</p>"},{"location":"data-sources/builtin-toolsets/slab/#configuration","title":"Configuration","text":"Holmes CLIRobusta Helm Chart <p>First, set the environment variable: <pre><code>export SLAB_API_KEY=\"&lt;your Slab API key&gt;\"\n</code></pre></p> <p>Then add the following to ~/.holmes/config.yaml. Create the file if it doesn't exist: <pre><code>toolsets:\n    slab:\n        enabled: true\n</code></pre></p> <p>After making changes to your configuration, run: <pre><code>holmes toolset refresh\n</code></pre></p> <pre><code>holmes:\n    additionalEnvVars:\n        - name: SLAB_API_KEY\n          value: \"&lt;your Slab API key&gt;\"\n    toolsets:\n        slab:\n            enabled: true\n</code></pre> <p>Update your Helm values and run a Helm upgrade: <pre><code>helm upgrade robusta robusta/robusta --values=generated_values.yaml --set clusterName=&lt;YOUR_CLUSTER_NAME&gt;\n</code></pre></p> <p>To test, run:</p> <pre><code>holmes ask \"Why is my pod failing, if it's a crashloopbackoff use the runbooks from Slab\"\n</code></pre>"},{"location":"data-sources/builtin-toolsets/slab/#capabilities","title":"Capabilities","text":"<p>The table below describes the specific capabilities provided by this toolset. HolmesGPT can decide to invoke any of these capabilities when answering questions or investigating issues.</p> Tool Name Description fetch_slab_document Fetch a document from Slab. Use this to fetch runbooks if they are present before starting your investigation."},{"location":"development/","title":"Development","text":"<p>Extend HolmesGPT with custom integrations and contribute to the project.</p>"},{"location":"development/#available-development-guides","title":"Available Development Guides","text":"<ul> <li>Contributing Guidelines - How to contribute to the HolmesGPT project</li> </ul>"},{"location":"development/#evaluations","title":"Evaluations","text":"<ul> <li>Evaluations Overview - Understanding HolmesGPT's evaluation framework</li> <li>Writing Evaluations - Create your own evaluation tests</li> <li>Reporting with Braintrust - Analyze evaluation results</li> </ul>"},{"location":"development/#development-setup","title":"Development Setup","text":"<p>To start developing with HolmesGPT:</p> <ol> <li>Set up development environment - Local Kubernetes cluster and tools</li> <li>Clone the repository - Get the latest source code</li> <li>Build and test - Create your custom integrations</li> <li>Deploy and validate - Test in a development environment</li> </ol>"},{"location":"development/#common-development-tasks","title":"Common Development Tasks","text":"<p>Help improve HolmesGPT:</p> <ul> <li>Fix bugs and improve performance</li> <li>Add new built-in toolsets</li> <li>Enhance documentation</li> <li>Share examples and best practices</li> </ul>"},{"location":"development/#development-resources","title":"Development Resources","text":"<ul> <li>Source Code: GitHub Repository</li> <li>Issue Tracker: GitHub Issues</li> <li>Community: Slack Channel</li> <li>Documentation: You're reading it!</li> </ul>"},{"location":"development/#getting-started","title":"Getting Started","text":"<p>New to HolmesGPT development? Start with:</p> <ol> <li>Contributing Guidelines - Understand the development process</li> <li>Evaluations Overview - Learn about the evaluation framework</li> </ol> <p>Ready to contribute? Begin with Contributing Guidelines.</p>"},{"location":"development/evals/","title":"HolmesGPT Evaluations","text":"<p>HolmesGPT uses automated evaluations (evals) to ensure consistent performance across different LLM models and to catch regressions during development. These evaluations test the system's ability to correctly diagnose Kubernetes issues.</p> <ul> <li>Writing Evaluations - Learn how to create new test cases and evaluations</li> </ul>"},{"location":"development/evals/#overview","title":"Overview","text":"<p>The eval system comprises two main test suites:</p> <ul> <li>Ask Holmes: Tests single-question interactions with HolmesGPT</li> <li>Investigate: Tests HolmesGPT's ability to investigate specific issues reported by AlertManager</li> </ul> <p>Evals use fixtures that simulate real Kubernetes environments and tool outputs, allowing comprehensive testing without requiring live clusters.</p> <p>While results are tracked and analyzed using Braintrust, Braintrust is not necessary to writing, running and debugging evals.</p>"},{"location":"development/evals/#examples","title":"Examples","text":"Test suite Test case Status ask_holmes 01_how_many_pods \u26a0\ufe0f ask_holmes 02_what_is_wrong_with_pod \u2705 ask_holmes 02_what_is_wrong_with_pod_LOKI \u2705 ask_holmes 03_what_is_the_command_to_port_forward \u2705 ask_holmes 04_related_k8s_events \u2705 ask_holmes 05_image_version \u2705 ask_holmes 06_explain_issue \u2705 ask_holmes 07_high_latency \u2705 ask_holmes 07_high_latency_LOKI \u2705 ask_holmes 08_sock_shop_frontend \u2705 ask_holmes 09_crashpod \u2705 ask_holmes 10_image_pull_backoff \u2705 ask_holmes 11_init_containers \u2705 ask_holmes 12_job_crashing \u2705 ask_holmes 12_job_crashing_CORALOGIX \u2705 ask_holmes 12_job_crashing_LOKI \u26a0\ufe0f ask_holmes 13_pending_node_selector \u2705 ask_holmes 14_pending_resources \u2705 ask_holmes 15_failed_readiness_probe \u2705 ask_holmes 16_failed_no_toolset_found \u2705 ask_holmes 17_oom_kill \u2705 ask_holmes 18_crash_looping_v2 \u2705"},{"location":"development/evals/#test-status-legend","title":"Test Status Legend","text":"<ul> <li>\u2705 Successful: Test passed and meets quality standards</li> <li>\u26a0\ufe0f Warning: Test failed but is known to be flaky or expected to fail</li> <li>\u274c Failed: Test failed and should be fixed before merging</li> </ul>"},{"location":"development/evals/#why-evaluations-matter","title":"Why Evaluations Matter","text":"<p>Evaluations serve several critical purposes:</p> <ol> <li>Quality Assurance: Ensure HolmesGPT provides accurate diagnostics and recommendations</li> <li>Model Comparison: Compare performance across different LLM models (GPT-4, Claude, Gemini, etc.)</li> <li>Regression Testing: Catch performance degradations when updating code or dependencies</li> <li>Toolset Validation: Verify that new toolsets and integrations work correctly</li> <li>Continuous Improvement: Identify areas where HolmesGPT needs enhancement</li> </ol>"},{"location":"development/evals/#how-to-run-evaluations","title":"How to Run Evaluations","text":""},{"location":"development/evals/#prerequisites","title":"Prerequisites","text":"<pre><code>poetry install\n</code></pre>"},{"location":"development/evals/#basic-usage","title":"Basic Usage","text":"<p>Run all evaluations: <pre><code>poetry run pytest ./tests/llm/test_*.py --no-cov --disable-warnings\n</code></pre></p> <p>By default the tests load and present mock files to the LLM whenever it asks for them. If a mock file is not present for a tool call, the tool call is passed through to the live tool itself. In a lot of cases this can cause the eval to fail unless the live environment (k8s cluster) matches what the LLM expects.</p> <p>Run specific test suite: <pre><code>poetry run pytest ./tests/llm/test_ask_holmes.py --no-cov --disable-warnings\npoetry run pytest ./tests/llm/test_investigate.py --no-cov --disable-warnings\n</code></pre></p> <p>Run a specific test case: <pre><code>poetry run pytest ./tests/llm/test_ask_holmes.py -k \"01_how_many_pods\" --no-cov --disable-warnings\n</code></pre></p> <p>It is possible to investigate and debug why an eval fails by the output provided in the console. The output includes the correctness score, the reasoning for the score, information about what tools were called, the expected answer, as well as the LLM's answer.</p>"},{"location":"development/evals/#environment-variables","title":"Environment Variables","text":"<p>Configure evaluations using these environment variables:</p> Variable Example Description <code>MODEL</code> <code>MODEL=anthropic/claude-3-5-sonnet-20241022</code> Specify which LLM model to use <code>CLASSIFIER_MODEL</code> <code>CLASSIFIER_MODEL=gpt-4o</code> The LLM model to use for scoring the answer (LLM as judge). Defaults to <code>MODEL</code> <code>ITERATIONS</code> <code>ITERATIONS=3</code> Run each test multiple times for consistency checking <code>RUN_LIVE</code> <code>RUN_LIVE=true</code> Execute <code>before-test</code> and <code>after-test</code> commands, ignore mock files <code>UPLOAD_DATASET</code> <code>UPLOAD_DATASET=true</code> Sync dataset to external evaluation platform <code>EXPERIMENT_ID</code> <code>EXPERIMENT_ID=my_baseline</code> Custom experiment name for result tracking <code>BRAINTRUST_API_KEY</code> <code>BRAINTRUST_API_KEY=sk-...</code> Enable Braintrust integration for result tracking and CI/CD report generation <code>BRAINTRUST_ORG</code> <code>BRAINTRUST_ORG=my-org</code> Braintrust organization name (defaults to \"robustadev\")"},{"location":"development/evals/#simple-example","title":"Simple Example","text":"<p>Run a comprehensive evaluation: <pre><code>export MODEL=gpt-4o\n\n# Run with parallel execution for speed\npoetry run pytest -n 10 ./tests/llm/test_*.py --no-cov --disable-warnings\n</code></pre></p>"},{"location":"development/evals/#live-testing","title":"Live Testing","text":"<p>For tests that require actual Kubernetes resources: <pre><code>export RUN_LIVE=true\n\npoetry run pytest ./tests/llm/test_ask_holmes.py -k \"specific_test\" --no-cov --disable-warnings\n</code></pre></p> <p>Live testing requires a Kubernetes cluster and will execute <code>before-test</code> and <code>after-test</code> commands to set up/tear down resources. Not all tests support live testing. Some tests require manual setup.</p>"},{"location":"development/evals/#model-comparison-workflow","title":"Model Comparison Workflow","text":"<ol> <li> <p>Create Baseline: Run evaluations with a reference model    <pre><code>EXPERIMENT_ID=baseline_gpt4o MODEL=gpt-4o poetry run pytest -n 10 ./tests/llm/test_* --no-cov --disable-warnings\n</code></pre></p> </li> <li> <p>Test New Model: Run evaluations with the model you want to compare    <pre><code>EXPERIMENT_ID=test_claude35 MODEL=anthropic/claude-3-5-sonnet-20241022 poetry run pytest -n 10 ./tests/llm/test_*  --no-cov --disable-warnings\n</code></pre></p> </li> <li> <p>Compare Results: Use evaluation tracking tools to analyze performance differences</p> </li> </ol>"},{"location":"development/evals/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/evals/#common-issues","title":"Common Issues","text":"<ol> <li>Missing API keys: Some tests are skipped without proper API keys</li> <li>Live test failures: Ensure Kubernetes cluster access and proper permissions</li> <li>Mock file mismatches: Regenerate mocks with <code>generate_mocks: true</code></li> <li>Timeout errors: Increase test timeout or check network connectivity</li> </ol>"},{"location":"development/evals/#debug-mode","title":"Debug Mode","text":"<p>Enable verbose output: <pre><code>poetry run pytest -v -s ./tests/llm/test_ask_holmes.py -k \"specific_test\" --no-cov --disable-warnings\n</code></pre></p> <p>This shows detailed output including: - Expected vs actual results - Tool calls made by the LLM - Evaluation scores and rationales - Debugging information</p>"},{"location":"development/evals/reporting/","title":"Reporting with Braintrust","text":"<p>This guide explains how to use Braintrust to analyze evaluation results, debug failures, and compare model performance.</p> <ul> <li>Evaluations Overview - Introduction to HolmesGPT's evaluation system</li> <li>Writing Evaluations - Learn how to create new test cases and evaluations</li> </ul>"},{"location":"development/evals/reporting/#overview","title":"Overview","text":"<p>Braintrust is a platform for tracking and analyzing LLM evaluations. HolmesGPT evals can be used without Braintrust but using Braintrust has a few advantages:</p> <ul> <li>We can track how Holmes perform over time</li> <li>It's easier to run and debug many evals with Braintrust over simpler pytests because Braintrust organises the different components of a HolmesGPT investigation like the input, tool calls, reasoning for scoring, etc.</li> </ul>"},{"location":"development/evals/reporting/#setting-up-braintrust","title":"Setting Up Braintrust","text":""},{"location":"development/evals/reporting/#1-create-account","title":"1. Create Account","text":"<ol> <li>Visit braintrust.dev</li> <li>Sign up for an account</li> <li>Create a new project (e.g., \"HolmesGPT\")</li> </ol>"},{"location":"development/evals/reporting/#2-get-api-key","title":"2. Get API Key","text":"<ol> <li>Click your profile icon (top right)</li> <li>Go to Settings \u2192 API Keys</li> <li>Generate a new API key</li> <li>Copy the key (starts with <code>sk-</code>)</li> </ol>"},{"location":"development/evals/reporting/#3-configure-environment","title":"3. Configure Environment","text":"<pre><code>export BRAINTRUST_API_KEY=sk-your-api-key-here\n</code></pre>"},{"location":"development/evals/reporting/#running-evaluations-with-braintrust","title":"Running Evaluations with Braintrust","text":""},{"location":"development/evals/reporting/#basic-evaluation-run","title":"Basic Evaluation Run","text":"<pre><code>export BRAINTRUST_API_KEY=sk-your-key\nexport UPLOAD_DATASET=true\n\npytest ./tests/llm/test_ask_holmes.py\n</code></pre>"},{"location":"development/evals/reporting/#named-experiment","title":"Named Experiment","text":"<pre><code>export EXPERIMENT_ID=baseline_gpt4o\nexport MODEL=gpt-4o\npytest -n 10 ./tests/llm/test_*.py\n</code></pre>"},{"location":"development/evals/reporting/#key-environment-variables","title":"Key Environment Variables","text":"Variable Purpose <code>UPLOAD_DATASET</code> Sync test cases to Braintrust <code>EXPERIMENT_ID</code> Name your experiment run. This makes it easier to find and track in Braintrust's UI <code>MODEL</code> The LLM model for Holmes to use <code>CLASSIFIER_MODEL</code> The LLM model to use for scoring the answer (LLM as judge)"},{"location":"development/evals/reporting/#analyzing-evaluation-results","title":"Analyzing Evaluation Results","text":""},{"location":"development/evals/reporting/#output","title":"Output","text":"<p>The main Span of an evaluation will present the input (either the AlertManager issue or the user's question for Ask Holmes) as well as HolmesGPT's answer.</p> <p></p>"},{"location":"development/evals/reporting/#score-types","title":"Score Types","text":"<p>Correctness Score: - Measures accuracy of LLM responses - Values: 0 or 1 - Shows how well output matches expectations</p> <p></p>"},{"location":"development/evals/reporting/#debugging-failed-evaluations","title":"Debugging Failed Evaluations","text":""},{"location":"development/evals/reporting/#1-identify-failing-tests","title":"1. Identify Failing Tests","text":"<p>In the experiment view: - Sort by score (ascending) to see worst performers - Filter by specific score types - Look for patterns in failures</p>"},{"location":"development/evals/reporting/#2-examine-tool-call-traces","title":"2. Examine Tool Call Traces","text":"<p>Click on a failing test to see: - Input: The original prompt/question - Tool Calls: Which tools the LLM invoked - Tool Results: What data each tool returned - Output: The LLM's final response - Expected: What the test expected</p> <p></p>"},{"location":"development/evals/reporting/#3-common-failure-patterns","title":"3. Common Failure Patterns","text":"<p>Low Correctness Score: - LLM missed key information in tool outputs - Response doesn't address the core question - Factual errors in the analysis</p> <p>Low Context Score: - LLM didn't reference important context items - May indicate prompt engineering issues - Could suggest irrelevant context was provided</p> <p>Missing Tool Calls: - LLM didn't invoke necessary tools - Check if tool descriptions are clear - Verify mock data is realistic</p>"},{"location":"development/evals/reporting/#4-debug-example","title":"4. Debug Example","text":"<p>Failing Test: \"02_what_is_wrong_with_pod\" - Score: Correctness 0.2, Context 0.1 - Issue: LLM said \"pod is healthy\" but expected \"CrashLoopBackOff detected\"</p> <p>Investigation: 1. Check <code>kubectl_describe.txt</code> mock - contains correct CrashLoopBackOff status 2. Verify <code>kubectl_logs.txt</code> shows crash errors 3. Review LLM's tool calls - did it call <code>kubectl_describe</code>? 4. Examine LLM output - did it misinterpret the kubectl output?</p> <p>Solution: Update mock files to be more explicit about the crash status</p>"},{"location":"development/evals/writing/","title":"Writing Evaluations","text":"<p>This guide explains how to create new evaluations for HolmesGPT. Evaluations test the system's ability to correctly diagnose issues and provide accurate recommendations.</p> <ul> <li>Evaluations Overview - Introduction to HolmesGPT's evaluation system</li> <li>Reporting with Braintrust - Analyze results and debug failures using Braintrust</li> </ul>"},{"location":"development/evals/writing/#overview","title":"Overview","text":"<p>HolmesGPT supports two types of evaluations:</p> <ol> <li>Ask Holmes Tests: Chat-like interactions (<code>tests/llm/test_ask_holmes.py</code>)</li> <li>Investigation Tests: Issue analysis for events triggered by AlertManager (<code>tests/llm/test_investigate.py</code>)</li> </ol> <p>Each test consists of: - A test case definition (<code>test_case.yaml</code>) - Mock tool outputs (e.g., <code>kubectl_describe.txt</code>) - Optional Kubernetes manifests for live testing - Optional custom toolset configurations</p>"},{"location":"development/evals/writing/#high-level-steps","title":"High-Level Steps","text":"<ol> <li>Choose test type: Ask Holmes vs Investigation. Choose Ask Holmes for most use cases. Choose Investigations for issues triggered by AlertManager</li> <li>Create a test folder: Use numbered naming convention</li> <li>Define your test case:</li> <li>Create <code>test_case.yaml</code> with prompt and expectations</li> <li>Define kubectl or helm setup and teardown manifests</li> <li>Generate mock data: Using a live system</li> <li>Set evaluation criteria: Define minimum scores for test success</li> <li>Test and iterate: Run the test and refine as needed</li> </ol>"},{"location":"development/evals/writing/#step-by-step-example-creating-an-ask-holmes-test","title":"Step-by-Step Example: Creating an Ask Holmes Test","text":"<p>Let's create a simple test that asks about pod health status.</p>"},{"location":"development/evals/writing/#step-1-create-test-folder","title":"Step 1: Create Test Folder","text":"<pre><code>mkdir tests/llm/fixtures/test_ask_holmes/99_pod_health_check\ncd tests/llm/fixtures/test_ask_holmes/99_pod_health_check\n</code></pre>"},{"location":"development/evals/writing/#step-2-create-test_caseyaml","title":"Step 2: Create test_case.yaml","text":"<pre><code>user_prompt: 'Is the nginx pod healthy?'\nexpected_output:\n  - nginx pod is healthy\nevaluation:\n  correctness: 1\nbefore_test: kubectl apply -f ./manifest.yaml\nafter_test: kubectl delete -f ./manifest.yaml\n</code></pre> <ul> <li><code>user_prompt</code>: This is the question that will trigger Holmes' investigation</li> <li><code>expected_output</code>: This is a list of expected elements that MUST be found in Holmes' answer. The combination of these elements lead to a <code>correctness</code> score based on HolmesGPT's output. This <code>expected_output</code> will be compared against HolmesGPT's answer and evaluated by a LLM ('LLM as judge'). The resulting score is called <code>correctness</code> and is a binary score with a value of either <code>0</code> or <code>1</code>. HolmesGPT's answer is score <code>0</code> is any of the expected element is not present in the answer, <code>1</code> if all expected elements are preent in the answer.</li> <li><code>evaluation.correctness</code>: This is the expected correctness score and is used for pytest to fail the test. This expected <code>correctness</code> score should be <code>0</code> unless you expect HolmesGPT to systematically succeed the evaluation. Because of this, it is important for <code>expected_output</code> to be reduced to the minimally accepted output from HolmesGPT.</li> <li><code>before_test</code> and <code>after_test</code>: These are setup and teardown steps to reproduce the test on a fresh environment. It is important for these to be present because as HolmesGPT's code, prompt and toolset evolve the mocks become insufficient or inaccurate. These scripts are run automatically when the env var <code>RUN_LIVE=true</code> is set</li> </ul>"},{"location":"development/evals/writing/#step-3-generate-mock-tool-outputs","title":"Step 3: Generate Mock Tool Outputs","text":"<p>Create mock files that simulate kubectl command outputs.</p> <p>The best way to do this is to:</p> <ol> <li>Deploy the test case you want to build an eval for in a kubernetes cluster (run the <code>before_test</code> script manually)</li> <li>Configure HolmesGPT to connect to the cluster (via kubectl and any other relevant toolsets)</li> <li>Enable the auto generation of mock files by setting <code>generate_mocks: True</code> in your <code>test_case.yaml</code></li> <li>Repeatedly run the eval with <code>ITERATIONS=100 pytest tests/llm/test_ask_holmes.py -k 99_pod_health_check</code></li> <li>Removing the prefix <code>.AUTOGENERATED</code> from all autogenerated files</li> </ol>"},{"location":"development/evals/writing/#step-4-run-the-test","title":"Step 4: Run the Test","text":"<pre><code>pytest ./tests/llm/test_ask_holmes.py -k \"99_pod_health_check\" -v\n</code></pre>"},{"location":"development/evals/writing/#test-case-configuration-reference","title":"Test Case Configuration Reference","text":""},{"location":"development/evals/writing/#common-fields","title":"Common Fields","text":"Field Type Required Description <code>user_prompt</code> string Yes The question or prompt for HolmesGPT <code>expected_output</code> string or list Yes Expected elements in the response <code>evaluation</code> dict No Minimum scores for test to pass"},{"location":"development/evals/writing/#ask-holmes-specific-fields","title":"Ask Holmes Specific Fields","text":"Field Type Description <code>before_test</code> string Command to run before test (requires <code>RUN_LIVE=true</code>) <code>after_test</code> string Command to run after test cleanup <code>generate_mocks</code> boolean Whether to generate new mock files"},{"location":"development/evals/writing/#investigation-specific-fields","title":"Investigation Specific Fields","text":"Field Type Description <code>expected_sections</code> dict Required/prohibited sections in output"},{"location":"development/evals/writing/#example-complex-investigation-test","title":"Example: Complex Investigation Test","text":"<pre><code>user_prompt: \"Investigate this CrashLoopBackOff issue\"\nexpected_output:\n  - Pod is experiencing CrashLoopBackOff\n  - Container exits with code 1 due to configuration error\n  - Missing environment variable DATABASE_URL\nexpected_sections:\n  \"Root Cause Analysis\":\n    - CrashLoopBackOff\n    - configuration error\n  \"Recommended Actions\": true\n  \"External Links\": false\nevaluation:\n  correctness: 0\nbefore_test: kubectl apply -f ./manifest.yaml\nafter_test: kubectl delete -f ./manifest.yaml\n</code></pre>"},{"location":"development/evals/writing/#mock-file-generation","title":"Mock File Generation","text":""},{"location":"development/evals/writing/#automatic-generation","title":"Automatic Generation","text":"<p>Set <code>generate_mocks: true</code> in <code>test_case.yaml</code> and run with a live cluster:</p> <pre><code>ITERATIONS=100 pytest ./tests/llm/test_ask_holmes.py -k \"your_test\"\n</code></pre> <p>This captures real tool outputs and saves them as mock files.</p>"},{"location":"development/evals/writing/#manual-creation","title":"Manual Creation","text":"<p>Create files matching the tool names used by HolmesGPT:</p> <ul> <li><code>kubectl_describe.txt</code> - Pod/resource descriptions</li> <li><code>kubectl_logs.txt</code> - Container logs</li> <li><code>kubectl_events.txt</code> - Kubernetes events</li> <li><code>prometheus_query.txt</code> - Metrics data</li> <li><code>fetch_loki_logs.txt</code> - Log aggregation results</li> </ul>"},{"location":"development/evals/writing/#naming-convention","title":"Naming Convention","text":"<p>Mock files follow the pattern: <code>{tool_name}_{additional_context}.txt</code></p> <p>Examples: - <code>kubectl_describe_pod_nginx_default.txt</code> - <code>kubectl_logs_all_containers_nginx.txt</code> - <code>execute_prometheus_range_query.txt</code></p>"},{"location":"development/evals/writing/#toolset-configuration","title":"Toolset Configuration","text":"<p>Some tests require specific toolsets. Create a <code>toolsets.yaml</code> file:</p> <pre><code>toolsets:\n  - name: kubernetes\n    enabled: true\n  - name: prometheus\n    enabled: true\n    config:\n      prometheus_url: http://localhost:9090 # requires port-forward\n  - name: grafana_loki\n    enabled: true\n    config:\n      base_url: http://localhost:3000 # requires port-forward\n      api_key: \"{{env.GRAFANA_API_KEY}}\"\n      grafana_datasource_uid: \"{{env.GRAFANA_DATASOURCE_UID}}\"\n</code></pre>"},{"location":"development/evals/writing/#live-testing-with-real-resources","title":"Live Testing with Real Resources","text":"<p>For tests that need actual Kubernetes resources:</p>"},{"location":"development/evals/writing/#step-1-create-manifest","title":"Step 1: Create Manifest","text":"<p>manifest.yaml: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: test-nginx\n  template:\n    metadata:\n      labels:\n        app: test-nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.20\n        ports:\n        - containerPort: 80\n</code></pre></p>"},{"location":"development/evals/writing/#step-2-configure-setupteardown","title":"Step 2: Configure Setup/Teardown","text":"<pre><code>user_prompt: 'How is the test-nginx deployment performing?'\nbefore-test: kubectl apply -f manifest.yaml\nafter-test: kubectl delete -f manifest.yaml\n# ... rest of configuration\n</code></pre>"},{"location":"development/evals/writing/#step-3-run-live-test","title":"Step 3: Run Live Test","text":"<pre><code>RUN_LIVE=true pytest ./tests/llm/test_ask_holmes.py -k \"your_test\"\n</code></pre> <p><code>RUN_LIVE</code> is currently incompatible with <code>ITERATIONS</code> &gt; 1.</p>"},{"location":"development/evals/writing/#evaluation-scoring","title":"Evaluation Scoring","text":""},{"location":"development/evals/writing/#correctness-score","title":"Correctness Score","text":"<p>Measures how well the output matches expected elements: - 1: Match - 0: Mismatch</p>"},{"location":"development/evals/writing/#setting-minimum-scores","title":"Setting Minimum Scores","text":"<pre><code>evaluation:\n  correctness: 1\n</code></pre>"},{"location":"development/evals/writing/#tagging","title":"Tagging","text":"<p>Evals are tagged for organisation and reporting purposes. The valid tags are defined in the test constants file in the repository.</p>"},{"location":"development/evals/writing/#best-practices","title":"Best Practices","text":""},{"location":"development/evals/writing/#test-design","title":"Test Design","text":"<ol> <li>Start simple: Begin with basic scenarios before complex edge cases</li> <li>Clear expectations: Write specific, measurable expected outputs</li> <li>Realistic scenarios: Base tests on actual user problems</li> <li>Incremental complexity: Build from simple to complex test cases</li> </ol>"},{"location":"development/evals/writing/#mock-data-quality","title":"Mock Data Quality","text":"<ol> <li>Representative data: Use realistic kubectl outputs and logs</li> <li>Error scenarios: Include failure modes and edge cases</li> <li>Consistent formatting: Match actual tool output formats</li> <li>Sufficient detail: Include enough information for proper diagnosis</li> <li>Run repeatedly: Run mock generation many times to ensure all investigative paths are covered by mock files</li> </ol>"},{"location":"development/evals/writing/#troubleshooting-test-creation","title":"Troubleshooting Test Creation","text":""},{"location":"development/evals/writing/#common-issues","title":"Common Issues","text":"<p>Test always fails with low correctness score: - Check if expected_output matches actual LLM capabilities - Verify mock data provides sufficient information - Consider lowering score threshold temporarily</p> <p>Missing tool outputs: - Ensure mock files are named correctly - Check that required toolsets are enabled - Verify mock file content is properly formatted</p> <p>Inconsistent results: - Run multiple iterations: <code>ITERATIONS=5</code> - Check for non-deterministic elements in prompts - Consider using temperature=0 for more consistent outputs</p>"},{"location":"development/evals/writing/#debugging-commands","title":"Debugging Commands","text":"<pre><code># Verbose output showing all details\npytest -v -s ./tests/llm/test_ask_holmes.py -k \"your_test\"\n\n# Generate fresh mocks from live system\n# set `generate_mocks: True` in test_case.yaml` and then:\npytest ./tests/llm/test_ask_holmes.py -k \"your_test\"\n</code></pre> <p>This completes the evaluation writing guide. The next step is setting up reporting and analysis using Braintrust.</p>"},{"location":"installation/cli-installation/","title":"Install CLI","text":"<p>Run HolmesGPT from your terminal as a standalone CLI tool.</p>"},{"location":"installation/cli-installation/#installation-options","title":"Installation Options","text":"Homebrew (Mac/Linux)PipxFrom Source (Poetry)Docker Container <ol> <li> <p>Add our tap:    <pre><code>brew tap robusta-dev/homebrew-holmesgpt\n</code></pre></p> </li> <li> <p>Install HolmesGPT:    <pre><code>brew install holmesgpt\n</code></pre></p> </li> <li> <p>To upgrade to the latest version:    <pre><code>brew upgrade holmesgpt\n</code></pre></p> </li> <li> <p>Verify installation:    <pre><code>holmes ask --help\n</code></pre></p> </li> </ol> <ol> <li> <p>Install pipx</p> </li> <li> <p>Install HolmesGPT:    <pre><code>pipx install holmesgpt\n</code></pre></p> </li> <li> <p>Verify installation:    <pre><code>holmes ask --help\n</code></pre></p> </li> </ol> <p>For development or custom builds:</p> <ol> <li> <p>Install Poetry</p> </li> <li> <p>Install HolmesGPT:    <pre><code>git clone https://github.com/robusta-dev/holmesgpt.git\ncd holmesgpt\npoetry install --no-root\n</code></pre></p> </li> <li> <p>Verify installation:    <pre><code>poetry run holmes ask --help\n</code></pre></p> </li> </ol> <p>Run HolmesGPT using the prebuilt Docker container:</p> <pre><code>docker run -it --net=host \\\n  -e OPENAI_API_KEY=\"your-api-key\" \\\n  -v ~/.holmes:/root/.holmes \\\n  -v ~/.aws:/root/.aws \\\n  -v ~/.config/gcloud:/root/.config/gcloud \\\n  -v $HOME/.kube/config:/root/.kube/config \\\n  us-central1-docker.pkg.dev/genuine-flight-317411/devel/holmes ask \"what pods are unhealthy and why?\"\n</code></pre> <p>Note: Pass environment variables using <code>-e</code> flags. An example for OpenAI is shown above. Adjust it for other AI providers by passing <code>-e GEMINI_API_KEY</code>, <code>-e ANTHROPIC_API_KEY</code>, etc.</p>"},{"location":"installation/cli-installation/#quick-start","title":"Quick Start","text":"<p>After installation, choose your AI provider and follow the steps below. See supported AI Providers for more details.</p> OpenAI (Default)Azure OpenAIAWS BedrockAnthropic ClaudeGoogle GeminiGoogle Vertex AIOllama <ol> <li> <p>Set up API key:     <pre><code>export OPENAI_API_KEY=\"your-api-key\"\n</code></pre></p> <p>See OpenAI Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\"\n</code></pre></p> </li> </ol> <ol> <li> <p>Set up API key:     <pre><code>export AZURE_API_VERSION=\"2024-02-15-preview\"\nexport AZURE_API_BASE=\"https://your-resource.openai.azure.com\"\nexport AZURE_API_KEY=\"your-azure-api-key\"\n</code></pre></p> <p>See Azure OpenAI Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"azure/&lt;your-model-name&gt;\"\n</code></pre></p> </li> </ol> <ol> <li> <p>Set up API key:     <pre><code>export AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_DEFAULT_REGION=\"your-region\"\n</code></pre></p> <p>See AWS Bedrock Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"bedrock/&lt;your-model-name&gt;\"\n</code></pre></p> <p>Note: You must install <code>boto3&gt;=1.28.57</code> and replace <code>&lt;your-model-name&gt;</code> with an actual model name like <code>anthropic.claude-3-5-sonnet-20240620-v1:0</code>. See Finding Available Models for instructions.</p> </li> </ol> <p>Ask follow-up questions to refine your investigation</p> <ol> <li> <p>Set up API key:     <pre><code>export ANTHROPIC_API_KEY=\"your-api-key\"\n</code></pre></p> <p>See Anthropic Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"anthropic/&lt;your-model-name&gt;\"\n</code></pre></p> </li> </ol> <ol> <li> <p>Set up API key:     <pre><code>export GEMINI_API_KEY=\"your-gemini-api-key\"\n</code></pre></p> <p>See Google Gemini Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"gemini/&lt;your-gemini-model&gt;\"\n</code></pre></p> </li> </ol> <ol> <li> <p>Set up credentials:     <pre><code>export VERTEXAI_PROJECT=\"your-project-id\"\nexport VERTEXAI_LOCATION=\"us-central1\"\nexport GOOGLE_APPLICATION_CREDENTIALS=\"path/to/service-account-key.json\"\n</code></pre></p> <p>See Google Vertex AI Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"vertex_ai/&lt;your-vertex-model&gt;\"\n</code></pre></p> </li> </ol> <ol> <li> <p>Set up API key:     No API key required for local Ollama installation.</p> <p>See Ollama Configuration for more details.</p> </li> <li> <p>Create a test pod to investigate:     <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask your first question:     <pre><code>holmes ask \"what is wrong with the user-profile-import pod?\" --model=\"ollama/&lt;your-model-name&gt;\"\n</code></pre></p> </li> </ol> <p>Note: Only LiteLLM supported Ollama models work with HolmesGPT. Check the LiteLLM Ollama documentation for supported models.</p>"},{"location":"installation/cli-installation/#next-steps","title":"Next Steps","text":"<ul> <li>Add Data Sources - Use built-in toolsets to connect with ArgoCD, Confluence, and monitoring tools</li> <li>Connect Remote MCP Servers - Extend capabilities with external MCP servers</li> </ul>"},{"location":"installation/cli-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"installation/kubernetes-installation/","title":"Install Helm Chart","text":"<p>Deploy HolmesGPT as a service in your Kubernetes cluster with an HTTP API.</p> <p>When to use the Helm chart?</p> <p>Most users should use the CLI or UI/TUI instead. Using the Helm chart is only recommended if you're building a custom integration over an HTTP API.</p>"},{"location":"installation/kubernetes-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster</li> <li>Helm</li> <li>kubectl configured to access your cluster</li> <li>Supported AI Provider API key.</li> </ul>"},{"location":"installation/kubernetes-installation/#installation","title":"Installation","text":"<ol> <li> <p>Add the Helm repository: <pre><code>helm repo add robusta https://robusta-charts.storage.googleapis.com\nhelm repo update\n</code></pre></p> </li> <li> <p>Create <code>values.yaml</code> file:</p> <p>Create a <code>values.yaml</code> file to configure HolmesGPT with your API key:</p> OpenAIAnthropicAzure OpenAIOther AI Providers <pre><code># values.yaml\nadditionalEnvVars:\n- name: OPENAI_API_KEY\n  value: \"your-openai-api-key\"\n# Or load from secret:\n# - name: OPENAI_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: openai-api-key\n</code></pre> <pre><code># values.yaml\nadditionalEnvVars:\n- name: ANTHROPIC_API_KEY\n  value: \"your-anthropic-api-key\"\n# Or load from secret:\n# - name: ANTHROPIC_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: anthropic-api-key\n</code></pre> <pre><code># values.yaml\nadditionalEnvVars:\n- name: AZURE_API_KEY\n  value: \"your-azure-api-key\"\n- name: AZURE_API_BASE\n  value: \"https://your-resource.openai.azure.com/\"\n- name: AZURE_API_VERSION\n  value: \"2024-02-15-preview\"\n# Or load from secret:\n# - name: AZURE_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: azure-api-key\n# - name: AZURE_API_BASE\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: azure-api-base\n</code></pre> <pre><code># values.yaml\nadditionalEnvVars:\n# Google Gemini\n- name: GEMINI_API_KEY\n  value: \"your-gemini-api-key\"\n# AWS Bedrock\n- name: AWS_ACCESS_KEY_ID\n  value: \"your-access-key\"\n- name: AWS_SECRET_ACCESS_KEY\n  value: \"your-secret-key\"\n- name: AWS_REGION_NAME\n  value: \"your-region\"\n# Or load from secret:\n# - name: GEMINI_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: gemini-api-key\n</code></pre> <p>Configuration Guide: Each AI provider requires different environment variables. See the AI Providers documentation for the specific environment variables needed for your chosen provider, then add them to the <code>additionalEnvVars</code> section as shown above.</p> </li> <li> <p>Install HolmesGPT: <pre><code>helm install holmesgpt robusta/holmes -f values.yaml\n</code></pre></p> </li> </ol>"},{"location":"installation/kubernetes-installation/#usage","title":"Usage","text":"<p>After installation, test the service with a simple API call:</p> <pre><code># Port forward to access the service locally\n# Note: Service name is {release-name}-holmes\nkubectl port-forward svc/holmesgpt-holmes 8080:80\n\n# If you used a different release name or namespace:\n# kubectl port-forward svc/{your-release-name}-holmes 8080:80 -n {your-namespace}\n\n# Test with a basic question\ncurl -X POST http://localhost:8080/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ask\": \"list pods in namespace default?\"}'\n</code></pre> <p>Note: Responses may take some time when HolmesGPT needs to gather large amounts of data to answer your question. Streaming APIs are coming soon to stream results.</p> <p>For complete API documentation, see the HTTP API Reference.</p>"},{"location":"installation/kubernetes-installation/#upgrading","title":"Upgrading","text":"<pre><code>helm repo update\nhelm upgrade holmesgpt robusta/holmes -f values.yaml\n</code></pre>"},{"location":"installation/kubernetes-installation/#uninstalling","title":"Uninstalling","text":"<pre><code>helm uninstall holmesgpt\n</code></pre>"},{"location":"installation/kubernetes-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"installation/python-installation/","title":"Install Python SDK","text":"<p>Embed HolmesGPT in your own applications for programmatic root cause analysis, based on observability data.</p>"},{"location":"installation/python-installation/#install-holmesgpt-python-package","title":"Install HolmesGPT Python Package","text":"<pre><code>pip install holmesgpt # Installs latest stable version\n</code></pre> <p>Install unreleased version from GitHub: <pre><code>pip install \"https://github.com/robusta-dev/holmesgpt/archive/refs/heads/master.zip\"\n</code></pre></p>"},{"location":"installation/python-installation/#quick-start","title":"Quick Start","text":"<pre><code>import os\nfrom holmes.config import Config\nfrom holmes.plugins.prompts import load_and_render_prompt\n\nprint(\"\ud83d\ude80 Initializing HolmesGPT...\")\n\n# Create configuration\nprint(\"Creating configuration...\")\nconfig = Config(\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    max_steps=10\n)\nprint(f\"\u2705 Configuration created with model: {config.model}\")\n\n# Create AI instance\nprint(\"Creating AI instance...\")\nai = config.create_console_toolcalling_llm()\nprint(\"\u2705 AI instance ready\")\n\n# Ask a question\nprint(\"Loading system prompt...\")\nsystem_prompt = load_and_render_prompt(\n    \"builtin://generic_ask.jinja2\",\n    {\"toolsets\": ai.tool_executor.toolsets}\n)\nprint(\"\u2705 System prompt loaded\")\n\nprint(\"\\n\ud83d\udd0d Asking: 'what pods are failing in production?'\")\nprint(\"Holmes is thinking...\")\nresponse = ai.prompt_call(system_prompt, \"what pods are failing in production?\")\nprint(f\"Holmes: {response.result}\")\n</code></pre>"},{"location":"installation/python-installation/#tool-details-example","title":"Tool Details Example","text":"<p>Here's a complete working example that shows detailed progress, available tools, toolsets, and which tools Holmes uses:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nComplete example of using HolmesGPT Python SDK with progress tracking\n\"\"\"\n\nimport os\nfrom holmes.config import Config\nfrom holmes.plugins.prompts import load_and_render_prompt\n\ndef main():\n    print(\"\ud83d\ude80 Starting HolmesGPT Python SDK Example\")\n    print(\"=\" * 60)\n\n    # Set API key (you can also set OPENAI_API_KEY environment variable)\n    api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n\n    print(\"Step 1: Creating configuration...\")\n    # Create configuration\n    config = Config(\n        api_key=api_key,\n        model=\"gpt-4o\",\n        max_steps=10\n    )\n    print(f\"\u2705 Configuration created with model: {config.model}\")\n\n    print(\"\\nStep 2: Creating AI instance...\")\n    # Create AI instance\n    ai = config.create_console_toolcalling_llm()\n    print(\"\u2705 AI instance created successfully\")\n\n    print(\"\\nStep 3: Listing available toolsets...\")\n    # Show available toolsets\n    toolsets = ai.tool_executor.toolsets\n    print(f\"Loaded {len(toolsets)} toolsets:\")\n    for toolset in toolsets:\n        print(f\"   \u2022 {toolset.name} ({'enabled' if toolset.enabled else 'disabled'})\")\n\n    print(\"\\nStep 4: Listing available tools from loaded toolsets...\")\n    # Show available tools\n    available_tools = list(ai.tool_executor.tools_by_name.keys())\n    print(f\"Listed {len(available_tools)} tools:\")\n    for tool in sorted(available_tools):\n        print(f\"   \u2022 {tool}\")\n\n    print(\"\\nStep 5: Loading system prompt...\")\n    # Load system prompt\n    system_prompt = load_and_render_prompt(\n        \"builtin://generic_ask.jinja2\",\n        {\"toolsets\": ai.tool_executor.toolsets}\n    )\n    print(\"\u2705 System prompt loaded successfully\")\n    print(f\"Prompt length: {len(system_prompt)} characters\")\n\n    print(\"\\nStep 6: Asking questions...\")\n    # Ask questions\n    questions = [\n        \"what pods are failing in production?\",\n        \"show me recent kubernetes events\",\n        \"what are the resource usage patterns in my cluster?\"\n    ]\n\n    for i, question in enumerate(questions, 1):\n        print(f\"\\n\ud83d\udd0d Question {i}/{len(questions)}: {question}\")\n        print(\"=\" * 60)\n\n        try:\n            print(\"Holmes is thinking...\")\n            response = ai.prompt_call(system_prompt, question)\n            print(f\"Holmes: {response.result}\")\n\n            # Show tools that were used\n            if response and response.tool_calls:\n                tool_names = [tool.tool_name for tool in response.tool_calls]\n                if tool_names:\n                    print(f\"\\nTools used: {tool_names}\")\n\n                    # Print contents of each tool response\n                    print(\"\\nTool responses:\")\n                    for j, tool in enumerate(response.tool_calls, 1):\n                        print(f\"\\n   {j}. {tool.tool_name}:\")\n                        print(f\"      Result: {tool.result}\")\n                        if hasattr(tool, 'error') and tool.error:\n                            print(f\"      Error: {tool.error}\")\n\n        except Exception as e:\n            print(f\"\u274c Error: {e}\")\n\n        print(\"-\" * 60)\n\n    print(\"\\n\u2705 Example completed!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Save this as <code>holmesgpt_tool_details_example.py</code> and run:</p> <pre><code># Make sure your API key is set\nexport OPENAI_API_KEY=\"your-actual-api-key\"\n\n# Run the example\npython holmesgpt_tool_details_example.py\n</code></pre> <p>This will show you:</p> <ul> <li>Configuration creation progress</li> <li>List of available tools (kubectl, prometheus, etc.)</li> <li>List of available toolsets and their status</li> <li>System prompt loading progress</li> <li>Progress for each question being asked</li> <li>Which tools Holmes used for each question</li> </ul>"},{"location":"installation/python-installation/#follow-up-questions-example","title":"Follow-up Questions Example","text":"<p>Here's how to ask follow-up questions that maintain conversation context:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nExample showing how to ask follow-up questions with conversation context\n\"\"\"\n\nimport os\nfrom holmes.config import Config\nfrom holmes.plugins.prompts import load_and_render_prompt\nfrom holmes.core.prompt import build_initial_ask_messages\nfrom rich.console import Console\n\ndef main():\n    print(\"\ud83d\ude80 Starting HolmesGPT Follow-up Questions Example\")\n    print(\"=\" * 60)\n\n    # Create configuration\n    config = Config(\n        api_key=os.getenv(\"OPENAI_API_KEY\"),\n        model=\"gpt-4o\",\n        max_steps=10\n    )\n\n    # Create AI instance and console\n    ai = config.create_console_toolcalling_llm()\n    console = Console()\n\n    # Load system prompt\n    system_prompt = load_and_render_prompt(\n        \"builtin://generic_ask.jinja2\",\n        {\"toolsets\": ai.tool_executor.toolsets}\n    )\n\n    # First question\n    print(\"\\n\ud83d\udd0d First Question:\")\n    first_question = \"what pods are failing in my cluster?\"\n    print(f\"User: {first_question}\")\n\n    # Build initial messages (system + first user message)\n    messages = build_initial_ask_messages(\n        console, system_prompt, first_question, None\n    )\n\n    # Call AI with initial messages\n    print(\"Holmes is thinking...\")\n    response = ai.call(messages)\n    messages = response.messages  # Update messages with full conversation\n\n    print(f\"Holmes: {response.result}\")\n\n    # Follow-up question\n    followup_question = \"Can you show me the logs for those failing pods?\"\n\n    print(f\"\\n\ud83d\udd0d Follow-up Question:\")\n    print(f\"User: {followup_question}\")\n\n    # Add the follow-up question to the conversation\n    messages.append({\"role\": \"user\", \"content\": followup_question})\n\n    # Call AI with updated message history\n    print(\"Holmes is thinking...\")\n    response = ai.call(messages)\n    messages = response.messages  # Update messages with latest response\n\n    print(f\"Holmes: {response.result}\")\n\n    # Show tools used\n    if response.tool_calls:\n        tool_names = [tool.tool_name for tool in response.tool_calls]\n        print(f\"Tools used: {tool_names}\")\n\n    print(\"\\n\u2705 Conversation completed!\")\n    print(f\"Total messages in conversation: {len(messages)}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Key Points for Follow-up Questions:</p> <ol> <li>Use <code>build_initial_ask_messages()</code> for the first question</li> <li>Use <code>ai.call(messages)</code> instead of <code>ai.prompt_call()</code></li> <li>Update messages after each response: <code>messages = response.messages</code></li> <li>Append new questions: <code>messages.append({\"role\": \"user\", \"content\": question})</code></li> <li>Messages contain full conversation history for context</li> </ol>"},{"location":"installation/python-installation/#configuration-options","title":"Configuration Options","text":""},{"location":"installation/python-installation/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from holmes.config import Config\n\n# Basic configuration example\nconfig = Config(\n    api_key=\"your-api-key\",\n    model=\"gpt-4o\",  # or \"claude-3-sonnet\", \"gpt-3.5-turbo\", etc.\n    max_steps=10\n)\n\n# Minimal configuration (API key only)\nconfig = Config(api_key=\"your-api-key\")\n\n# Environment-based configuration\nconfig = Config()  # Will auto-detect API key from OPENAI_API_KEY\n</code></pre>"},{"location":"installation/python-installation/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>from holmes.config import Config\n\n# Complete configuration with custom toolsets and runbooks\nconfig = Config(\n    # LLM settings\n    api_key=\"your-api-key\",\n    model=\"gpt-4o\",\n    max_steps=10,\n\n    # Custom toolsets and runbooks\n    custom_toolsets=[\"/path/to/custom/toolset.yaml\"],\n    custom_runbooks=[\"/path/to/custom/runbook.yaml\"],\n)\n</code></pre>"},{"location":"installation/python-installation/#api-reference","title":"API Reference","text":""},{"location":"installation/python-installation/#config","title":"Config","text":"<p>Main configuration class for HolmesGPT.</p> <p>Constructor Parameters:</p> <ul> <li><code>api_key</code> (str, optional) - LLM API key (can also use environment variables)</li> <li><code>model</code> (str, optional) - Model to use (default: \"gpt-4o\")</li> <li><code>max_steps</code> (int, optional) - Maximum investigation steps (default: 10)</li> <li><code>custom_toolsets</code> (list, optional) - Custom toolset file paths</li> <li><code>custom_runbooks</code> (list, optional) - Custom runbook file paths</li> </ul> <p>Class Methods:</p> <ul> <li><code>Config.load_from_file(path)</code> - Load configuration from YAML file</li> <li><code>Config.load_from_env()</code> - Load configuration from environment variables</li> </ul> <p>Instance Methods:</p> <ul> <li><code>create_console_toolcalling_llm()</code> - Create AI instance for investigations</li> </ul>"},{"location":"installation/python-installation/#toolcallingllm","title":"ToolCallingLLM","text":"<p>Main AI instance for running investigations.</p> <p>Methods:</p> <ul> <li><code>prompt_call(system_prompt, user_prompt)</code> - Ask a question and get response</li> <li><code>call(messages)</code> - Call with full message history</li> </ul>"},{"location":"installation/python-installation/#environment-variables","title":"Environment Variables","text":"<p>Instead of passing <code>api_key</code> to the Config constructor, you can set these environment variables and use <code>Config()</code> without parameters:</p> <pre><code># AI Provider (choose one)\nexport OPENAI_API_KEY=\"your-openai-key\"\nexport ANTHROPIC_API_KEY=\"your-anthropic-key\"\nexport GOOGLE_API_KEY=\"your-google-key\"\n\n# Optional: Custom configuration\nexport HOLMES_CONFIG_PATH=\"/path/to/config.yaml\"\nexport HOLMES_LOG_LEVEL=\"INFO\"\n</code></pre> <p>Usage with environment variables: <pre><code>import os\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n\nconfig = Config()  # Will auto-detect API key from environment\n</code></pre></p>"},{"location":"installation/python-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"installation/ui-installation/","title":"Install UI/TUI","text":"<p>Use HolmesGPT through graphical and terminal interfaces via third-party integrations.</p>"},{"location":"installation/ui-installation/#k9s-plugin","title":"K9s Plugin","text":"<p>Integrate HolmesGPT into your K9s Kubernetes terminal for instant analysis.</p> <p></p>"},{"location":"installation/ui-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>K9s must be installed - See the K9s installation guide</li> <li>HolmesGPT CLI and API key - Follow the CLI Installation Guide to install Holmes and configure your AI provider</li> </ul>"},{"location":"installation/ui-installation/#plugin-options","title":"Plugin Options","text":"Basic Plugin (Shift + H) - Quick investigation with predefined question <p>Add to your K9s plugins configuration file:</p> <ul> <li>Linux: <code>~/.config/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>macOS: <code>~/Library/Application Support/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>Windows: <code>%APPDATA%/k9s/plugins.yaml</code></li> </ul> <p>Read more about K9s plugins here and check your plugin path here.</p> <pre><code>plugins:\n  holmesgpt:\n    shortCut: Shift-H\n    description: Ask HolmesGPT\n    scopes:\n      - all\n    command: bash\n    background: false\n    confirm: false\n    args:\n      - -c\n      - |\n        # Check if we're already using the correct context\n        CURRENT_CONTEXT=$(kubectl config current-context 2&gt;/dev/null || echo \"\")\n        if [ \"$CURRENT_CONTEXT\" = \"$CONTEXT\" ]; then\n          # Already using the correct context, run HolmesGPT directly\n          holmes ask \"why is $NAME of $RESOURCE_NAME in -n $NAMESPACE not working as expected\"\n        else\n          # Create temporary kubeconfig to avoid changing user's system context\n          # K9s passes $CONTEXT but we need to ensure HolmesGPT uses the same context\n          # without permanently switching the user's kubectl context\n          TEMP_KUBECONFIG=$(mktemp)\n          kubectl config view --raw &gt; $TEMP_KUBECONFIG\n          KUBECONFIG=$TEMP_KUBECONFIG kubectl config use-context $CONTEXT\n          # KUBECONFIG environment variable is passed to holmes and all its child processes\n          KUBECONFIG=$TEMP_KUBECONFIG holmes ask \"why is $NAME of $RESOURCE_NAME in -n $NAMESPACE not working as expected\"\n          rm -f $TEMP_KUBECONFIG\n        fi\n        echo \"Press 'q' to exit\"\n        while : ; do\n        read -n 1 k &lt;&amp;1\n        if [[ $k = q ]] ; then\n        break\n        fi\n        done\n</code></pre> Advanced Plugin (Shift + Q) - Interactive plugin with custom questions <p>Add to your K9s plugins configuration file:</p> <ul> <li>Linux: <code>~/.config/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>macOS: <code>~/Library/Application Support/k9s/plugins.yaml</code> or <code>~/.k9s/plugins.yaml</code></li> <li>Windows: <code>%APPDATA%/k9s/plugins.yaml</code></li> </ul> <p>Read more about K9s plugins here and check your plugin path here.</p> <pre><code>plugins:\n  custom-holmesgpt:\n    shortCut: Shift-Q\n    description: Custom HolmesGPT Ask\n    scopes:\n      - all\n    command: bash\n    background: false\n    confirm: false\n    args:\n      - -c\n      - |\n        INSTRUCTIONS=\"# Edit the line below. Lines starting with '#' will be ignored.\"\n        DEFAULT_ASK_COMMAND=\"why is $NAME of $RESOURCE_NAME in -n $NAMESPACE not working as expected\"\n        QUESTION_FILE=$(mktemp)\n\n        echo \"$INSTRUCTIONS\" &gt; \"$QUESTION_FILE\"\n        echo \"$DEFAULT_ASK_COMMAND\" &gt;&gt; \"$QUESTION_FILE\"\n\n        # Open the line in the default text editor\n        ${EDITOR:-nano} \"$QUESTION_FILE\"\n\n        # Read the modified line, ignoring lines starting with '#'\n        user_input=$(grep -v '^#' \"$QUESTION_FILE\")\n\n        echo \"Running: holmes ask '$user_input'\"\n        # Check if we're already using the correct context\n        CURRENT_CONTEXT=$(kubectl config current-context 2&gt;/dev/null || echo \"\")\n        if [ \"$CURRENT_CONTEXT\" = \"$CONTEXT\" ]; then\n          # Already using the correct context, run HolmesGPT directly\n          holmes ask \"$user_input\"\n        else\n          # Create temporary kubeconfig to avoid changing user's system context\n          # K9s passes $CONTEXT but we need to ensure HolmesGPT uses the same context\n          # without permanently switching the user's kubectl context\n          TEMP_KUBECONFIG=$(mktemp)\n          kubectl config view --raw &gt; $TEMP_KUBECONFIG\n          KUBECONFIG=$TEMP_KUBECONFIG kubectl config use-context $CONTEXT\n          # KUBECONFIG environment variable is passed to holmes and all its child processes\n          KUBECONFIG=$TEMP_KUBECONFIG holmes ask \"$user_input\"\n          rm -f $TEMP_KUBECONFIG\n        fi\n        echo \"Press 'q' to exit\"\n        while : ; do\n        read -n 1 k &lt;&amp;1\n        if [[ $k = q ]] ; then\n        break\n        fi\n        done\n</code></pre>"},{"location":"installation/ui-installation/#usage","title":"Usage","text":"<ol> <li>Run K9s and select any Kubernetes resource</li> <li>Press Shift + H for quick analysis or Shift + Q for custom questions</li> </ol>"},{"location":"installation/ui-installation/#web-ui-robusta","title":"Web UI (Robusta)","text":"<p>The fastest way to use HolmesGPT is via the managed Robusta SaaS platform.</p> <p></p>"},{"location":"installation/ui-installation/#get-started","title":"Get Started","text":"<ol> <li>Sign up: platform.robusta.dev</li> <li>Connect your cluster: Follow the in-app wizard to install the Robusta agent and configure data sources.</li> <li> <p>Investigate: Use the \"Ask Holmes\" chat to analyze alerts or ask questions like:</p> <ol> <li>\u201cWhat pods are failing in production?\u201d</li> <li>\u201cWhy did this alert fire?\u201d</li> </ol> </li> </ol>"},{"location":"installation/ui-installation/#slack-bot-robusta","title":"Slack Bot (Robusta)","text":"<p>First install Robusta SaaS, then tag HolmesGPT in any Slack message for instant analysis.</p> <p></p>"},{"location":"installation/ui-installation/#setup-slack-bot","title":"Setup Slack Bot","text":""},{"location":"installation/ui-installation/#need-help","title":"Need Help?","text":"<ul> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> <li>Troubleshooting guide - Common issues and solutions</li> </ul>"},{"location":"reference/helm-configuration/","title":"Helm Configuration","text":"<p>Configuration reference for HolmesGPT Helm chart.</p> <p>Quick Links:</p> <ul> <li>Installation Tutorial - Step-by-step setup guide</li> <li>values.yaml - Complete configuration reference</li> <li>HTTP API Reference - Test your deployment</li> </ul>"},{"location":"reference/helm-configuration/#basic-configuration","title":"Basic Configuration","text":"<pre><code># values.yaml\n# Image settings\nimage: holmes:0.0.0\nregistry: robustadev\n\n# Logging level\nlogLevel: INFO\n\n# send exceptions to sentry\nenableTelemetry: true\n\n# Resource limits\nresources:\n  requests:\n    cpu: 100m\n    memory: 1024Mi\n  limits:\n    memory: 1024Mi\n\n# Enabled/disable/customize specific toolsets\ntoolsets:\n  kubernetes/core:\n    enabled: true\n  kubernetes/logs:\n    enabled: true\n  robusta:\n    enabled: true\n  internet:\n    enabled: true\n  prometheus/metrics:\n    enabled: true\n  ...\n</code></pre> <p>Note: After making changes to your configuration, run <code>holmes toolset refresh</code> to apply the changes.</p>"},{"location":"reference/helm-configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"reference/helm-configuration/#essential-settings","title":"Essential Settings","text":"Parameter Description Default <code>additionalEnvVars</code> Environment variables (API keys, etc.) <code>[]</code> <code>toolsets</code> Enable/disable specific toolsets (see values.yaml) <code>openshift</code> Enable OpenShift compatibility mode <code>false</code> <code>image</code> HolmesGPT image name <code>holmes:0.0.0</code> <code>registry</code> Container registry <code>robustadev</code> <code>logLevel</code> Log level (DEBUG, INFO, WARN, ERROR) <code>INFO</code> <code>enableTelemetry</code> Send exception reports to sentry <code>true</code> <code>certificate</code> Base64 encoded custom CA certificate for outbound HTTPS requests (e.g., LLM API via proxy) <code>\"\"</code> <code>sentryDSN</code> Sentry DSN for telemetry (see values.yaml)"},{"location":"reference/helm-configuration/#api-key-configuration","title":"API Key Configuration","text":"<p>The most important configuration is setting up API keys for your chosen AI provider:</p> <pre><code>additionalEnvVars:\n- name: OPENAI_API_KEY\n  value: \"your-api-key\"\n# Or load from secret:\n# - name: OPENAI_API_KEY\n#   valueFrom:\n#     secretKeyRef:\n#       name: holmes-secrets\n#       key: openai-api-key\n</code></pre>"},{"location":"reference/helm-configuration/#toolset-configuration","title":"Toolset Configuration","text":"<p>Control which capabilities HolmesGPT has access to:</p> <pre><code>toolsets:\n  kubernetes/core:\n    enabled: true      # Core Kubernetes functionality\n  kubernetes/logs:\n    enabled: true      # Kubernetes logs access\n  robusta:\n    enabled: true      # Robusta platform integration\n  internet:\n    enabled: true      # Internet access for documentation\n  prometheus/metrics:\n    enabled: true      # Prometheus metrics access\n</code></pre>"},{"location":"reference/helm-configuration/#service-account-configuration","title":"Service Account Configuration","text":"<pre><code># Create service account (default: true)\ncreateServiceAccount: true\n\n# Use custom service account name\ncustomServiceAccountName: \"\"\n\n# Service account settings\nserviceAccount:\n  imagePullSecrets: []\n  annotations: {}\n\n# Custom RBAC rules\ncustomClusterRoleRules: []\n</code></pre>"},{"location":"reference/helm-configuration/#resource-configuration","title":"Resource Configuration","text":"<pre><code>resources:\n  requests:\n    cpu: 100m\n    memory: 1024Mi\n  limits:\n    cpu: 100m        # Optional CPU limit\n    memory: 1024Mi\n</code></pre>"},{"location":"reference/helm-configuration/#toolset-configuration_1","title":"Toolset Configuration","text":"<p>Enable or disable specific toolsets:</p> <pre><code>toolsets:\n  kubernetes/core:\n    enabled: true      # Core Kubernetes functionality\n  kubernetes/logs:\n    enabled: true      # Kubernetes logs access\n  robusta:\n    enabled: true      # Robusta platform integration\n  internet:\n    enabled: true      # Internet access for documentation\n  prometheus/metrics:\n    enabled: true      # Prometheus metrics access\n</code></pre>"},{"location":"reference/helm-configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"reference/helm-configuration/#scheduling","title":"Scheduling","text":"<pre><code># Node selection\n# nodeSelector:\n#   kubernetes.io/os: linux\n\n# Pod affinity/anti-affinity\naffinity: {}\n\n# Tolerations\ntolerations: []\n\n# Priority class\npriorityClassName: \"\"\n</code></pre>"},{"location":"reference/helm-configuration/#additional-configuration","title":"Additional Configuration","text":"<pre><code># Additional environment variables\nadditionalEnvVars: []\nadditional_env_vars: []  # Legacy, use additionalEnvVars instead\n\n# Image pull secrets\nimagePullSecrets: []\n\n# Additional volumes\nadditionalVolumes: []\n\n# Additional volume mounts\nadditionalVolumeMounts: []\n\n# OpenShift compatibility mode\nopenshift: false\n\n# Post-processing configuration\nenablePostProcessing: false\npostProcessingPrompt: \"builtin://generic_post_processing.jinja2\"\n\n# Account creation\nenableAccountsCreate: true\n\n# MCP servers configuration\nmcp_servers: {}\n\n# Model list configuration\nmodelList: {}\n</code></pre>"},{"location":"reference/helm-configuration/#example-configurations","title":"Example Configurations","text":""},{"location":"reference/helm-configuration/#minimal-setup","title":"Minimal Setup","text":"<pre><code># values.yaml\nimage: holmes:0.0.0\nregistry: robustadev\nlogLevel: INFO\nenableTelemetry: false\n\nresources:\n  requests:\n    cpu: 100m\n    memory: 512Mi\n  limits:\n    memory: 512Mi\n\ntoolsets:\n  kubernetes/core:\n    enabled: true\n  kubernetes/logs:\n    enabled: true\n  robusta:\n    enabled: false\n  internet:\n    enabled: false\n  prometheus/metrics:\n    enabled: false\n</code></pre>"},{"location":"reference/helm-configuration/#openshift-setup","title":"OpenShift Setup","text":"<pre><code># values.yaml\nopenshift: true\ncreateServiceAccount: true\n\nresources:\n  requests:\n    cpu: 100m\n    memory: 1024Mi\n  limits:\n    memory: 1024Mi\n\ntoolsets:\n  kubernetes/core:\n    enabled: true\n  kubernetes/logs:\n    enabled: true\n</code></pre>"},{"location":"reference/helm-configuration/#configuration-validation","title":"Configuration Validation","text":"<pre><code># Validate configuration\nhelm template holmesgpt robusta/holmes -f values.yaml\n\n# Dry run installation\nhelm install holmesgpt robusta/holmes -f values.yaml --dry-run\n\n# Check syntax\nyamllint values.yaml\n</code></pre>"},{"location":"reference/helm-configuration/#complete-reference","title":"Complete Reference","text":"<p>For the complete and up-to-date configuration reference, see the actual <code>values.yaml</code> file in the repository.</p>"},{"location":"reference/http-api/","title":"HolmesGPT API Reference","text":""},{"location":"reference/http-api/#overview","title":"Overview","text":"<p>The HolmesGPT API provides endpoints for automated investigations, workload health checks, and conversational troubleshooting. This document describes each endpoint, its purpose, request fields, and example usage.</p>"},{"location":"reference/http-api/#endpoints","title":"Endpoints","text":""},{"location":"reference/http-api/#apichat-post","title":"<code>/api/chat</code> (POST)","text":"<p>Description: General-purpose chat endpoint for interacting with the AI assistant. Supports open-ended questions and troubleshooting.</p>"},{"location":"reference/http-api/#request-fields","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question conversation_history No list Conversation history (first message must be system) model No string Model name to use <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"What is the status of my cluster?\",\n    \"conversation_history\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n    ]\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"Your cluster is healthy. All nodes are ready and workloads are running as expected.\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"What is the status of my cluster?\"},\n    {\"role\": \"assistant\", \"content\": \"Your cluster is healthy. All nodes are ready and workloads are running as expected.\"}\n  ],\n  \"tool_calls\": [...],\n  \"follow_up_actions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apiinvestigate-post","title":"<code>/api/investigate</code> (POST)","text":"<p>Description: Initiate an automated investigation of an issue or incident.</p>"},{"location":"reference/http-api/#request-fields_1","title":"Request Fields","text":"Field Required Default Type Description source Yes string Source of the issue (e.g., \"prometheus\") title Yes string Title of the investigation description Yes string Description of the issue subject Yes object Subject details (e.g., resource info) context Yes object Additional context source_instance_id No \"ApiRequest\" string Source instance identifier include_tool_calls No false boolean Include tool calls in response include_tool_call_results No false boolean Include tool call results in response prompt_template No \"builtin://generic_investigation.jinja2\" string Prompt template to use sections No object Structured output sections model No string Model name to use <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/investigate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\": \"prometheus\",\n    \"title\": \"Pod CrashLoopBackOff\",\n    \"description\": \"Pod is crashing repeatedly\",\n    \"subject\": {\"namespace\": \"default\", \"pod\": \"my-pod\"},\n    \"context\": {},\n    \"include_tool_calls\": true,\n    \"model\": \"gpt-4o\"\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"The pod 'my-pod' in namespace 'default' is crashing due to an OOMKilled event. Consider increasing memory limits.\",\n  \"sections\": {\n    \"Alert Explanation\": \"...\",\n    \"Key Findings\": \"...\",\n    \"Conclusions and Possible Root Causes\": \"...\",\n    \"Next Steps\": \"...\",\n    \"App or Infra?\": \"...\",\n    \"External links\": \"...\"\n  },\n  \"tool_calls\": [\n    {\n      \"tool_call_id\": \"1\",\n      \"tool_name\": \"kubectl_logs\",\n      \"description\": \"Fetch pod logs\",\n      \"result\": {\"logs\": \"...\"}\n    }\n  ],\n  \"instructions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apistreaminvestigate-post","title":"<code>/api/stream/investigate</code> (POST)","text":"<p>Description: Same as <code>/api/investigate</code>, but returns results as a stream for real-time updates.</p>"},{"location":"reference/http-api/#request-fields_2","title":"Request Fields","text":"<p>Same as <code>/api/investigate</code>.</p> <p>Example <pre><code>curl -N -X POST http://&lt;HOLMES-URL&gt;/api/stream/investigate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\": \"prometheus\",\n    \"title\": \"Pod CrashLoopBackOff\",\n    \"description\": \"Pod is crashing repeatedly\",\n    \"subject\": {\"namespace\": \"default\", \"pod\": \"my-pod\"},\n    \"context\": {},\n    \"include_tool_calls\": true,\n    \"model\": \"gpt-4o\"\n  }'\n</code></pre></p> <p>Example Response (streamed) <pre><code>event: start_tool_calling\ndata: {\"tool_name\": \"kubectl_describe\", \"id\": \"call_0\"}\n\nevent: start_tool_calling\ndata: {\"tool_name\": \"kubectl_logs\", \"id\": \"call_1\"}\n\nevent: start_tool_calling\ndata: {\"tool_name\": \"kubectl_previous_logs\", \"id\": \"call_2\"}\n\nevent: start_tool_calling\ndata: {\"tool_name\": \"kubectl_memory_requests_namespace\", \"id\": \"call_3\"}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_3\", \"role\": \"tool\", \"description\": \"kubectl get pods -n default -o ...\", \"name\": \"kubectl_memory_requests_namespace\", \"result\": {...}}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_0\", \"role\": \"tool\", \"description\": \"kubectl describe pod my-pod -n default\", \"name\": \"kubectl_describe\", \"result\": {...}}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_2\", \"role\": \"tool\", \"description\": \"kubectl logs my-pod -n default --previous\", \"name\": \"kubectl_previous_logs\", \"result\": {...}}\n\nevent: tool_calling_result\ndata: {\"tool_call_id\": \"call_1\", \"role\": \"tool\", \"description\": \"kubectl logs my-pod -n default\", \"name\": \"kubectl_logs\", \"result\": {...}}\n\nevent: ai_answer_end\ndata: {\"sections\": {\"Alert Explanation\": ...}}\n</code></pre></p>"},{"location":"reference/http-api/#apiissue_chat-post","title":"<code>/api/issue_chat</code> (POST)","text":"<p>Description: Conversational interface for discussing a specific issue or incident, with context from a previous investigation.</p>"},{"location":"reference/http-api/#request-fields_3","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question investigation_result Yes object Previous investigation result (see below) issue_type Yes string Type of issue conversation_history No list Conversation history (first message must be system) model No string Model name to use <p>investigation_result object: - <code>result</code> (string, optional): Previous analysis - <code>tools</code> (list, optional): Tools used/results</p> <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/issue_chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"How do I fix this issue?\",\n    \"investigation_result\": {\n      \"result\": \"Pod crashed due to OOM.\",\n      \"tools\": []\n    },\n    \"issue_type\": \"CrashLoopBackOff\",\n    \"conversation_history\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n    ]\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"To fix the CrashLoopBackOff, increase the memory limit for the pod and check for memory leaks in the application.\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"How do I fix this issue?\"},\n    {\"role\": \"assistant\", \"content\": \"To fix the CrashLoopBackOff, increase the memory limit for the pod and check for memory leaks in the application.\"}\n  ],\n  \"tool_calls\": [...],\n  \"follow_up_actions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apiworkload_health_check-post","title":"<code>/api/workload_health_check</code> (POST)","text":"<p>Description: Performs a health check on a specified workload (e.g., a Kubernetes deployment).</p>"},{"location":"reference/http-api/#request-fields_4","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question resource Yes object Resource details (e.g., name, kind) alert_history_since_hours No 24 float How many hours back to check alerts alert_history No true boolean Whether to include alert history stored_instructions No true boolean Use stored instructions instructions No [] list Additional instructions include_tool_calls No false boolean Include tool calls in response include_tool_call_results No false boolean Include tool call results in response prompt_template No \"builtin://kubernetes_workload_ask.jinja2\" string Prompt template to use model No string Model name to use <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/workload_health_check \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"Why is my deployment unhealthy?\",\n    \"resource\": {\"name\": \"my-deployment\", \"kind\": \"Deployment\"},\n    \"alert_history_since_hours\": 12\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"Deployment 'my-deployment' is unhealthy due to repeated CrashLoopBackOff events.\",\n  \"sections\": null,\n  \"tool_calls\": [\n    {\n      \"tool_call_id\": \"2\",\n      \"tool_name\": \"kubectl_get_events\",\n      \"description\": \"Fetch recent events\",\n      \"result\": {\"events\": \"...\"}\n    }\n  ],\n  \"instructions\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apiworkload_health_chat-post","title":"<code>/api/workload_health_chat</code> (POST)","text":"<p>Description: Conversational interface for discussing the health of a workload.</p>"},{"location":"reference/http-api/#request-fields_5","title":"Request Fields","text":"Field Required Default Type Description ask Yes string User's question workload_health_result Yes object Previous health check result (see below) resource Yes object Resource details conversation_history No list Conversation history (first message must be system) model No string Model name to use <p>workload_health_result object: - <code>analysis</code> (string, optional): Previous analysis - <code>tools</code> (list, optional): Tools used/results</p> <p>Example <pre><code>curl -X POST http://&lt;HOLMES-URL&gt;/api/workload_health_chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"ask\": \"Check the workload health.\",\n    \"workload_health_result\": {\n      \"analysis\": \"Previous health check: all good.\",\n      \"tools\": []\n    },\n    \"resource\": {\"name\": \"my-deployment\", \"kind\": \"Deployment\"},\n    \"conversation_history\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n    ]\n  }'\n</code></pre></p> <p>Example Response <pre><code>{\n  \"analysis\": \"The deployment 'my-deployment' is healthy. No recent issues detected.\",\n  \"conversation_history\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Check the workload health.\"},\n    {\"role\": \"assistant\", \"content\": \"The deployment 'my-deployment' is healthy. No recent issues detected.\"}\n  ],\n  \"tool_calls\": [...]\n}\n</code></pre></p>"},{"location":"reference/http-api/#apimodel-get","title":"<code>/api/model</code> (GET)","text":"<p>Description: Returns a list of available AI models that can be used for investigations and chat.</p> <p>Example <pre><code>curl http://&lt;HOLMES-URL&gt;/api/model\n</code></pre></p> <p>Example Response <pre><code>{\n  \"model_name\": [\"gpt-4o\", \"azure/gpt-4o\", \"robusta\"]\n}\n</code></pre></p>"},{"location":"reference/troubleshooting/","title":"HolmesGPT Not Finding Any Issues? Here's Why.","text":""},{"location":"reference/troubleshooting/#1-truncation-too-much-data","title":"1. Truncation: Too Much Data","text":"<p>Data overflow causes important information to be truncated. See #437 for summarization improvements.</p> <p>Solution:</p> <ul> <li>Use specific namespaces and time ranges</li> <li>Target individual components instead of cluster-wide queries</li> </ul>"},{"location":"reference/troubleshooting/#2-missing-data-access","title":"2. Missing Data Access","text":"<p>HolmesGPT can't access logs, metrics, or traces from your observability stack.</p> <p>Solution:</p> <ul> <li>Verify toolset configuration connects to Prometheus/Grafana/logs</li> <li>Test connectivity: <code>kubectl exec -it &lt;holmes-pod&gt; -- curl http://prometheus:9090/api/v1/query?query=up</code></li> </ul>"},{"location":"reference/troubleshooting/#3-rbac-permissions","title":"3. RBAC Permissions","text":"<p>Service account lacks Kubernetes API permissions.</p> <p>Error Example: <pre><code>pods is forbidden: User \"system:serviceaccount:default:holmesgpt\" cannot get resource \"pods\"\n</code></pre></p> <p>Solution: <pre><code>rbac:\n  create: true\nrbacRules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"services\", \"events\", \"nodes\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre></p>"},{"location":"reference/troubleshooting/#4-unclear-prompts","title":"4. Unclear Prompts","text":"<p>Vague questions produce poor results.</p> <p>Bad:</p> <ul> <li>\"Why is my pod not working?\"</li> <li>\"Check if anything is wrong with my cluster\"</li> <li>\"Something is broken in production and users are complaining\"</li> <li>\"My deployment keeps failing but I don't know why\"</li> <li>\"Can you debug this issue I'm having with my application?\"</li> </ul> <p>Good:</p> <ul> <li>\"Why is payment-service pod restarting in production namespace?\"</li> <li>\"What caused memory spike in web-frontend deployment last hour?\"</li> </ul>"},{"location":"reference/troubleshooting/#5-model-issues","title":"5. Model Issues","text":"<p>Older LLM models lack reasoning capability for complex problems.</p> <p>Solution: <pre><code>config:\n  model: \"gpt-4o\"  # or anthropic/claude-3-5-sonnet-20241022\n  temperature: 0.1\n  maxTokens: 2000\n</code></pre></p> <p>Recommended Models:</p> <ul> <li><code>gpt-4o</code> - Best balance of speed/capability</li> <li><code>anthropic/claude-3-5-sonnet-20241022</code> - Superior reasoning</li> <li><code>gpt-4-turbo</code> - Fast analysis</li> </ul>"},{"location":"reference/troubleshooting/#still-stuck","title":"Still stuck?","text":"<p>Join our Slack community or open a GitHub issue for help.</p>"},{"location":"walkthrough/","title":"Walkthrough","text":"<p>Get started with HolmesGPT by running your first investigation.</p>"},{"location":"walkthrough/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>\u2705 HolmesGPT CLI installed - See CLI Installation Guide</li> <li>\u2705 AI provider API key configured - See AI Provider Setup</li> <li>\u2705 kubectl access to a Kubernetes cluster - Any cluster will work</li> </ul>"},{"location":"walkthrough/#run-your-first-investigation","title":"Run Your First Investigation","text":"<p>Let's investigate a pod with HolmesGPT to see the value it provides:</p> <ol> <li> <p>Create a test pod with an issue: <pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_node_selector.yaml\n</code></pre></p> </li> <li> <p>Ask Holmes to investigate:</p> OpenAI (Default)Azure OpenAIAnthropic ClaudeGoogle GeminiAWS BedrockOllama <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"azure/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"anthropic/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"google/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"bedrock/&lt;your-model-name&gt;\"\n</code></pre> <pre><code>holmes ask \"describe the user-profile-import pod and explain any issues\" --model=\"ollama/&lt;your-model-name&gt;\"\n</code></pre> </li> <li> <p>See the value:</p> <p>Holmes will analyze the pod, identify that it's stuck in \"Pending\" state due to an invalid node selector, and suggest specific remediation steps - all without you needing to manually run <code>kubectl describe</code>, check events, or dig through logs.</p> </li> </ol>"},{"location":"walkthrough/#what-you-just-experienced","title":"What You Just Experienced","text":"<p>HolmesGPT automatically:</p> <ul> <li>\u2705 Gathered context - Retrieved pod status, events, and related information</li> <li>\u2705 Identified the root cause - Invalid node selector preventing scheduling</li> <li>\u2705 Provided actionable solutions - Specific commands to fix the issue</li> <li>\u2705 Saved investigation time - No manual troubleshooting steps required</li> </ul>"},{"location":"walkthrough/#clean-up","title":"Clean Up","text":"<p>Remove the test pod:</p> <pre><code>kubectl delete pod user-profile-import\n</code></pre>"},{"location":"walkthrough/#next-steps","title":"Next Steps","text":"<ul> <li>Add integrations - Connect monitoring tools like Prometheus, Grafana, and DataDog</li> <li>Troubleshooting guide - Common issues and solutions</li> <li>Join our Slack - Get help from the community</li> <li>Request features on GitHub - Suggest improvements or report bugs</li> </ul>"},{"location":"walkthrough/investigating-prometheus-alerts/","title":"Investigating Prometheus Alerts","text":"<p>You can investigate Prometheus/AlertManager alerts using HolmesGPT by connecting it to your AlertManager instance. This allows you to run investigations on all active alerts or a specific alert and optionally send the results to a Slack channel.</p>"},{"location":"walkthrough/investigating-prometheus-alerts/#prerequisites","title":"Prerequisites","text":"<ul> <li>HolmesGPT CLI installed (installation guide)</li> <li>An AI provider API key configured (setup guide)</li> <li>Access to your AlertManager instance</li> </ul>"},{"location":"walkthrough/investigating-prometheus-alerts/#investigating-a-prometheus-alert-using-holmesgpt","title":"Investigating a Prometheus Alert Using HolmesGPT","text":""},{"location":"walkthrough/investigating-prometheus-alerts/#step-1-forward-alertmanager","title":"Step 1: Forward AlertManager","text":"<p>First, you need to forward the AlertManager service to your local machine so HolmesGPT can connect to it. Run the following command in your terminal:</p> <pre><code>kubectl port-forward svc/&lt;Your-Alertmanager-Service&gt; 9093:9093\n</code></pre>"},{"location":"walkthrough/investigating-prometheus-alerts/#step-2-create-a-test-alert","title":"Step 2: Create a Test Alert","text":"<p>Now we'll deploy a crashing workload and simulate an alert from AlertManager.</p> <p><pre><code>kubectl apply -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/crashpod/broken.yaml\n</code></pre> Since it takes some time for the alert to be generated, we will manually send a <code>KubePodCrashLooping</code> alert to AlertManager for testing purposes. To do this run: <pre><code># Send a KubePodCrashLooping alert directly to AlertManager\ncurl -X POST http://localhost:9093/api/v1/alerts \\\n  -H \"Content-Type: application/json\" \\\n  -d '[\n    {\n      \"labels\": {\n        \"alertname\": \"KubePodCrashLooping\",\n        \"severity\": \"warning\",\n        \"namespace\": \"default\",\n        \"pod\": \"payment-processing-worker\",\n        \"container\": \"worker\",\n        \"job\": \"kubernetes-pods\"\n      },\n      \"annotations\": {\n        \"description\": \"Pod default/payment-processing-worker is crash looping\",\n        \"summary\": \"Pod is in CrashLoopBackOff state\"\n      },\n      \"generatorURL\": \"http://prometheus:9090/graph?g0.expr=increase%28kube_pod_container_status_restarts_total%5B1h%5D%29%20%3E%205\",\n      \"startsAt\": \"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\"\n    }\n  ]'\n</code></pre> You should now see the <code>KubePodCrashLooping</code> alert in your AlertManager UI at <code>http://localhost:9093</code>.</p>"},{"location":"walkthrough/investigating-prometheus-alerts/#step-3-investigate-alerts","title":"Step 3: Investigate Alerts","text":"<p>Finally let's use the HolmesGPT <code>investigate</code> subcommand to investigate the alerts. Run the following command:</p> <p><pre><code>holmes investigate alertmanager --alertmanager-url http://localhost:9093\n</code></pre> </p> <p>By default, HolmesGPT will fetch all active alerts from AlertManager and investigate them.</p> <p>For our investigation, we will use the <code>--alertmanager-alertname</code> flag to focus on the specific <code>KubePodCrashLooping</code> alert we created earlier. <pre><code>holmes investigate alertmanager --alertmanager-url http://localhost:9093 --alertmanager-alertname \"KubePodCrashLooping\"\n</code></pre></p> <p> Once the investigation is complete, HolmesGPT will provide the potential Root Cause, next steps, and more.</p>"},{"location":"walkthrough/investigating-prometheus-alerts/#filtering-alerts","title":"Filtering Alerts","text":"<p>The <code>holmes investigate alertmanager</code> command supports many flags. For example, to investigate only critical alerts or alerts in a specific namespace, you can use the <code>--alertmanager-label</code> flag:</p> <pre><code># Critical alerts only\nholmes investigate alertmanager \\\n  --alertmanager-url http://localhost:9093 \\\n  --alertmanager-label \"severity=critical\"\n\n# Production namespace issues\nholmes investigate alertmanager \\\n  --alertmanager-url http://localhost:9093 \\\n  --alertmanager-label \"namespace=production\"\n</code></pre>"},{"location":"walkthrough/investigating-prometheus-alerts/#whats-next","title":"What's Next?","text":"<ul> <li>Add new data sources - Connect HolmesGPT to your databases, APM tools, and custom APIs for deeper investigations.</li> <li>Set up remote MCP - Add data sources as remote Model Context Protocol (MCP) servers.</li> </ul>"}]}